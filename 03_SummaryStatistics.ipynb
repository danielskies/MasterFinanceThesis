{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4c873-fedc-47df-93cd-3cb19cd48d3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def generate_cleaned_dataset_summary_stats(df):\n",
    "    \"\"\"\n",
    "    Creating summary stats for the cleaned dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"CLEANED DATASET SUMMARY STATISTICS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Dataset Shape: {df.shape[0]:,} rows × {df.shape[1]:,} columns\")\n",
    "    \n",
    "    # Basic dataset overview\n",
    "    print(f\"\\nDATASET OVERVIEW\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Panel structure\n",
    "    if 'Ticker' in df.columns and 'Year' in df.columns:\n",
    "        n_companies = df['Ticker'].nunique()\n",
    "        n_years = df['Year'].nunique()\n",
    "        year_range = f\"{df['Year'].min()}-{df['Year'].max()}\"\n",
    "        \n",
    "        print(f\"   Panel Structure:\")\n",
    "        print(f\"      Companies: {n_companies:,}\")\n",
    "        print(f\"      Years: {n_years} ({year_range})\")\n",
    "        print(f\"      Total observations: {df.shape[0]:,}\")\n",
    "        print(f\"      Average years per company: {df.shape[0]/n_companies:.1f}\")\n",
    "        \n",
    "        # Check balance\n",
    "        company_counts = df.groupby('Ticker')['Year'].count()\n",
    "        perfect_balance = (company_counts == n_years).sum()\n",
    "        print(f\"      Perfectly balanced companies: {perfect_balance:,} ({perfect_balance/n_companies:.1%})\")\n",
    "    \n",
    "    # Sector distribution\n",
    "    if 'sector_gsector' in df.columns:\n",
    "        print(f\"\\n   Sector Distribution (GICS):\")\n",
    "        sector_counts = df['sector_gsector'].value_counts().head(8)\n",
    "        for sector, count in sector_counts.items():\n",
    "            pct = (count / len(df)) * 100\n",
    "            print(f\"      {sector}: {count:,} obs ({pct:.1f}%)\")\n",
    "    \n",
    "    # AI factors analysis\n",
    "    print(f\"\\nAI FACTORS ANALYSIS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # AI factors by model\n",
    "    models = {\n",
    "        'GPT-4o': 'gpt4o',\n",
    "        'Gemini Flash 1.5': 'flash1_5', \n",
    "        'Gemini Flash 2.5': 'flash2_5'\n",
    "    }\n",
    "    \n",
    "    ai_dimensions = ['Strategic Depth', 'Disclosure Sentiment', 'AI Washing Index', \n",
    "                    'Forward-Looking', 'Talent & Investment']\n",
    "    \n",
    "    for model_name, model_key in models.items():\n",
    "        print(f\"\\n   {model_name}:\")\n",
    "        \n",
    "        # Check categorical distributions\n",
    "        for dimension in ai_dimensions:\n",
    "            col_name = f\"{dimension}_{model_key}\"\n",
    "            if col_name in df.columns:\n",
    "                values = df[col_name].dropna()\n",
    "                if len(values) > 0:\n",
    "                    completeness = len(values) / len(df) * 100\n",
    "                    unique_vals = values.nunique()\n",
    "                    top_value = values.value_counts().index[0]\n",
    "                    top_pct = (values.value_counts().iloc[0] / len(values)) * 100\n",
    "                    \n",
    "                    print(f\"      {dimension[:20]:20}: {completeness:5.1f}% complete, \"\n",
    "                          f\"{unique_vals} categories, top='{top_value}' ({top_pct:.1f}%)\")\n",
    "        \n",
    "        # Check composite score\n",
    "        composite_col = f'Cum_Score_{model_key}'\n",
    "        if composite_col in df.columns:\n",
    "            comp_values = df[composite_col].dropna()\n",
    "            if len(comp_values) > 0:\n",
    "                print(f\"      {'Composite Score':20}: mean={comp_values.mean():.2f}, \"\n",
    "                      f\"std={comp_values.std():.2f}, range=[{comp_values.min():.1f}, {comp_values.max():.1f}]\")\n",
    "    \n",
    "    # Fama-French factors\n",
    "    print(f\"\\nFAMA-FRENCH FACTORS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    ff_factors = ['ff_mktrf', 'ff_smb', 'ff_hml', 'ff_rmw', 'ff_cma', 'ff_rf', 'ff_umd']\n",
    "    \n",
    "    print(\"   Point-in-time Factors (at filing date):\")\n",
    "    for factor in ff_factors:\n",
    "        if factor in df.columns:\n",
    "            values = df[factor].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                print(f\"      {factor:10}: {completeness:5.1f}% complete, \"\n",
    "                      f\"mean={values.mean():8.4f}, std={values.std():8.4f}\")\n",
    "    \n",
    "    # Cumulative RF rates\n",
    "    rf_cols = ['rf_3m_cumulative', 'rf_6m_cumulative', 'rf_9m_cumulative', 'rf_12m_cumulative']\n",
    "    print(f\"\\n   Cumulative Risk-Free Rates:\")\n",
    "    for rf_col in rf_cols:\n",
    "        if rf_col in df.columns:\n",
    "            values = df[rf_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                horizon = rf_col.replace('rf_', '').replace('m_cumulative', '')\n",
    "                print(f\"      {horizon:2}m cumulative: {completeness:5.1f}% complete, \"\n",
    "                      f\"mean={values.mean():6.4f} ({values.mean()*100:.2f}%)\")\n",
    "    \n",
    "    # Stock prices and returns\n",
    "    print(f\"\\nSTOCK PRICES & RETURNS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Stock prices at different time points\n",
    "    price_cols = ['price_t0', 'price_t3', 'price_t6', 'price_t9', 'price_t12']\n",
    "    print(\"   Stock Prices:\")\n",
    "    for price_col in price_cols:\n",
    "        if price_col in df.columns:\n",
    "            values = df[price_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                horizon = price_col.replace('price_t', '')\n",
    "                horizon_label = 'filing' if horizon == '0' else f'{horizon}m after'\n",
    "                print(f\"      {horizon_label:12}: {completeness:5.1f}% complete, \"\n",
    "                      f\"median=${values.median():8.2f}, std=${values.std():8.2f}\")\n",
    "    \n",
    "    # Raw returns\n",
    "    return_cols = ['return_3mo', 'return_6mo', 'return_9mo', 'return_12mo']\n",
    "    print(f\"\\n   Raw Returns:\")\n",
    "    for ret_col in return_cols:\n",
    "        if ret_col in df.columns:\n",
    "            values = df[ret_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                horizon = ret_col.replace('return_', '').replace('mo', '')\n",
    "                print(f\"      {horizon:2}m horizon : {completeness:5.1f}% complete, \"\n",
    "                      f\"mean={values.mean():7.1%}, std={values.std():7.1%}\")\n",
    "    \n",
    "    # Excess returns\n",
    "    excess_cols = ['excess_return_3mo', 'excess_return_6mo', 'excess_return_9mo', 'excess_return_12mo']\n",
    "    print(f\"\\n   Excess Returns:\")\n",
    "    for exc_col in excess_cols:\n",
    "        if exc_col in df.columns:\n",
    "            values = df[exc_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                horizon = exc_col.replace('excess_return_', '').replace('mo', '')\n",
    "                \n",
    "                # Compare with raw return\n",
    "                raw_col = exc_col.replace('excess_', '')\n",
    "                if raw_col in df.columns:\n",
    "                    raw_values = df[raw_col].dropna()\n",
    "                    if len(raw_values) > 0:\n",
    "                        rf_impact = raw_values.mean() - values.mean()\n",
    "                        print(f\"      {horizon:2}m horizon : {completeness:5.1f}% complete, \"\n",
    "                              f\"mean={values.mean():7.1%}, RF impact={rf_impact:5.1%}\")\n",
    "                    else:\n",
    "                        print(f\"      {horizon:2}m horizon : {completeness:5.1f}% complete, \"\n",
    "                              f\"mean={values.mean():7.1%}\")\n",
    "                else:\n",
    "                    print(f\"      {horizon:2}m horizon : {completeness:5.1f}% complete, \"\n",
    "                          f\"mean={values.mean():7.1%}\")\n",
    "    \n",
    "    # Fundamental variables\n",
    "    print(f\"\\nFUNDAMENTAL VARIABLES\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Fund variables with descriptions\n",
    "    fund_mapping = {\n",
    "        'fund_atq': 'Total Assets',\n",
    "        'fund_niq': 'Net Income', \n",
    "        'fund_teqq': 'Shareholders Equity',\n",
    "        'fund_revty': 'Revenue',\n",
    "        'fund_dlttq': 'Long-term Debt',\n",
    "        'fund_cheq': 'Cash & Short-term Investments',\n",
    "        'fund_epsfxq': 'EPS Diluted',\n",
    "        'fund_cshoq': 'Common Shares Outstanding',\n",
    "        'fund_oiadpq': 'Operating Income After Depreciation'\n",
    "    }\n",
    "    \n",
    "    print(\"   Key Fundamental Variables:\")\n",
    "    for fund_col, description in fund_mapping.items():\n",
    "        if fund_col in df.columns:\n",
    "            values = df[fund_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                \n",
    "                # Format based on typical magnitude\n",
    "                if 'eps' in fund_col.lower():\n",
    "                    print(f\"      {description[:25]:25}: {completeness:5.1f}% complete, \"\n",
    "                          f\"median={values.median():8.2f}\")\n",
    "                else:\n",
    "                    print(f\"      {description[:25]:25}: {completeness:5.1f}% complete, \"\n",
    "                          f\"median={values.median():10.2e}\")\n",
    "    \n",
    "    # Calculated ratios\n",
    "    print(f\"\\nCALCULATED FINANCIAL RATIOS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Calculated ratios with descriptions\n",
    "    ratio_mapping = {\n",
    "        'calc_roa': 'Return on Assets',\n",
    "        'calc_roe': 'Return on Equity',\n",
    "        'calc_debt_to_assets': 'Debt to Assets',\n",
    "        'calc_debt_to_equity': 'Debt to Equity', \n",
    "        'calc_price_to_book': 'Price to Book',\n",
    "        'calc_price_to_earnings': 'Price to Earnings',\n",
    "        'calc_market_to_book': 'Market to Book',\n",
    "        'calc_log_total_assets': 'Log Total Assets',\n",
    "        'calc_log_market_cap': 'Log Market Cap',\n",
    "        'calc_profit_margin': 'Profit Margin',\n",
    "        'calc_operating_margin': 'Operating Margin',\n",
    "        'calc_asset_turnover': 'Asset Turnover'\n",
    "    }\n",
    "    \n",
    "    print(\"   Key Financial Ratios:\")\n",
    "    for ratio_col, description in ratio_mapping.items():\n",
    "        if ratio_col in df.columns:\n",
    "            values = df[ratio_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                \n",
    "                # Show percentiles for ratios with wide distributions\n",
    "                if any(x in ratio_col for x in ['price_to_earnings', 'market_to_book']):\n",
    "                    p25, p50, p75 = values.quantile([0.25, 0.5, 0.75])\n",
    "                    print(f\"      {description[:25]:25}: {completeness:5.1f}% complete, \"\n",
    "                          f\"p25={p25:6.1f}, p50={p50:6.1f}, p75={p75:6.1f}\")\n",
    "                else:\n",
    "                    print(f\"      {description[:25]:25}: {completeness:5.1f}% complete, \"\n",
    "                          f\"mean={values.mean():8.3f}, std={values.std():8.3f}\")\n",
    "    \n",
    "    # Sector classification\n",
    "    print(f\"\\nGICS SECTOR CLASSIFICATION\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    gics_mapping = {\n",
    "        'sector_gsector': 'GICS Sector',\n",
    "        'sector_ggroup': 'GICS Industry Group',\n",
    "        'sector_gind': 'GICS Industry', \n",
    "        'sector_gsubind': 'GICS Sub-Industry'\n",
    "    }\n",
    "    \n",
    "    print(\"   GICS Classification Levels:\")\n",
    "    for gics_col, description in gics_mapping.items():\n",
    "        if gics_col in df.columns:\n",
    "            values = df[gics_col].dropna()\n",
    "            if len(values) > 0:\n",
    "                completeness = len(values) / len(df) * 100\n",
    "                unique_vals = values.nunique()\n",
    "                print(f\"      {description[:20]:20}: {completeness:5.1f}% complete, \"\n",
    "                      f\"{unique_vals:3d} unique codes\")\n",
    "    \n",
    "    # Data quality summary\n",
    "    print(f\"\\nDATA QUALITY SUMMARY\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Completeness by major categories\n",
    "    category_completeness = {}\n",
    "    \n",
    "    # AI factors (use one representative column per model)\n",
    "    for model_name, model_key in models.items():\n",
    "        strategic_col = f'Strategic Depth_{model_key}'\n",
    "        if strategic_col in df.columns:\n",
    "            completeness = (df[strategic_col].notna().sum() / len(df)) * 100\n",
    "            category_completeness[f'AI Factors ({model_name})'] = completeness\n",
    "    \n",
    "    # FF factors\n",
    "    if 'ff_mktrf' in df.columns:\n",
    "        ff_completeness = (df['ff_mktrf'].notna().sum() / len(df)) * 100\n",
    "        category_completeness['Fama-French Factors'] = ff_completeness\n",
    "    \n",
    "    # Prices\n",
    "    if 'price_t0' in df.columns:\n",
    "        price_completeness = (df['price_t0'].notna().sum() / len(df)) * 100\n",
    "        category_completeness['Stock Prices'] = price_completeness\n",
    "    \n",
    "    # Returns\n",
    "    if 'return_3mo' in df.columns:\n",
    "        return_completeness = (df['return_3mo'].notna().sum() / len(df)) * 100\n",
    "        category_completeness['Returns (3m)'] = return_completeness\n",
    "    \n",
    "    # Fundamentals\n",
    "    if 'fund_atq' in df.columns:\n",
    "        fund_completeness = (df['fund_atq'].notna().sum() / len(df)) * 100\n",
    "        category_completeness['Fundamentals'] = fund_completeness\n",
    "    \n",
    "    # Calculated ratios\n",
    "    if 'calc_roa' in df.columns:\n",
    "        ratio_completeness = (df['calc_roa'].notna().sum() / len(df)) * 100\n",
    "        category_completeness['Calculated Ratios'] = ratio_completeness\n",
    "    \n",
    "    print(\"   Data Completeness by Category:\")\n",
    "    for category, completeness in category_completeness.items():\n",
    "        status = \"Complete\" if completeness > 95 else \"Good\" if completeness > 80 else \"Limited\"\n",
    "        print(f\"      {category[:30]:30}: {completeness:5.1f}% {status}\")\n",
    "    \n",
    "    # Overall assessment\n",
    "    avg_completeness = np.mean(list(category_completeness.values()))\n",
    "    print(f\"\\n   Overall Data Quality: {avg_completeness:.1f}%\")\n",
    "    \n",
    "    if avg_completeness > 90:\n",
    "        quality_rating = \"Excellent - Ready for analysis\"\n",
    "    elif avg_completeness > 80:\n",
    "        quality_rating = \"Good - Minor gaps acceptable\"\n",
    "    else:\n",
    "        quality_rating = \"Fair - Consider data imputation\"\n",
    "    \n",
    "    print(f\"      Rating: {quality_rating}\")\n",
    "    \n",
    "    # Analysis readiness summary\n",
    "    print(f\"\\nANALYSIS READINESS\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Count usable observations for key analyses\n",
    "    analysis_readiness = {}\n",
    "    \n",
    "    # AI factor analysis\n",
    "    if 'Strategic Depth_gpt4o' in df.columns and 'return_3mo' in df.columns:\n",
    "        ai_analysis_ready = df[['Strategic Depth_gpt4o', 'return_3mo']].dropna().shape[0]\n",
    "        analysis_readiness['AI Factor to 3m Returns'] = ai_analysis_ready\n",
    "    \n",
    "    # FF factor analysis  \n",
    "    if 'ff_mktrf' in df.columns and 'excess_return_3mo' in df.columns:\n",
    "        ff_analysis_ready = df[['ff_mktrf', 'excess_return_3mo']].dropna().shape[0]\n",
    "        analysis_readiness['FF Factors to Excess Returns'] = ff_analysis_ready\n",
    "    \n",
    "    # Fundamental analysis\n",
    "    if 'fund_atq' in df.columns and 'calc_roa' in df.columns:\n",
    "        fund_analysis_ready = df[['fund_atq', 'calc_roa']].dropna().shape[0]\n",
    "        analysis_readiness['Fundamentals to Ratios'] = fund_analysis_ready\n",
    "    \n",
    "    # Long-term analysis\n",
    "    if 'return_12mo' in df.columns and 'excess_return_12mo' in df.columns:\n",
    "        longterm_ready = df[['return_12mo', 'excess_return_12mo']].dropna().shape[0]\n",
    "        analysis_readiness['12-month Analysis'] = longterm_ready\n",
    "    \n",
    "    print(\"   Usable Observations for Key Analyses:\")\n",
    "    for analysis, count in analysis_readiness.items():\n",
    "        pct = (count / len(df)) * 100\n",
    "        status = \"Ready\" if pct > 80 else \"Limited\" if pct > 70 else \"Insufficient\"\n",
    "        print(f\"      {analysis[:30]:30}: {count:4,} obs ({pct:5.1f}%) {status}\")\n",
    "    \n",
    "    print(f\"\\nDataset summary complete - ready for analysis\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Load and analyze the cleaned dataset\n",
    "def load_and_analyze_cleaned_dataset():\n",
    "    \"\"\"\n",
    "    Load the cleaned dataset and generate summary statistics\n",
    "    \"\"\"\n",
    "    load_path = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered.csv\"\n",
    "    \n",
    "    print(\"Loading cleaned dataset\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Path: {load_path}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(load_path)\n",
    "        print(f\"Dataset loaded successfully\")\n",
    "        print(f\"Shape: {df.shape[0]:,} rows × {df.shape[1]:,} columns\")\n",
    "        \n",
    "        # Generate summary statistics\n",
    "        generate_cleaned_dataset_summary_stats(df)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running cleaned dataset summary statistics\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    df = load_and_analyze_cleaned_dataset()\n",
    "    \n",
    "    if df is not None:\n",
    "        print(f\"\\nAnalysis complete - dataset ready for research\")\n",
    "    else:\n",
    "        print(f\"\\nAnalysis failed - check dataset path and file integrity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240717a-cf38-492c-bad8-5092c89a3f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# load cleaned dataset\n",
    "load_path = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered.csv\"\n",
    "if 'df_clean' not in globals():\n",
    "    df = pd.read_csv(load_path)\n",
    "    df['CIK'] = df['CIK'].astype(str).str.zfill(10)\n",
    "    df['gvkey'] = df['gvkey'].astype(str).str.zfill(6)\n",
    "else:\n",
    "    df = df_clean.copy()\n",
    "\n",
    "# create output directory\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"gics mapping and hierarchical analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# define gics mappings (standard gics names)\n",
    "gics_sector_names = {\n",
    "    10: \"Energy\",\n",
    "    15: \"Materials\", \n",
    "    20: \"Industrials\",\n",
    "    25: \"Consumer Discretionary\",\n",
    "    30: \"Consumer Staples\",\n",
    "    35: \"Health Care\",\n",
    "    40: \"Financials\",\n",
    "    45: \"Information Technology\",\n",
    "    50: \"Communication Services\",\n",
    "    55: \"Utilities\",\n",
    "    60: \"Real Estate\"\n",
    "}\n",
    "\n",
    "# gics industry group mapping (level 2) - key groups\n",
    "gics_group_names = {\n",
    "    1010: \"Energy\",\n",
    "    1510: \"Materials\",\n",
    "    2010: \"Capital Goods\", 2020: \"Commercial & Professional Services\", 2030: \"Transportation\",\n",
    "    2510: \"Automobiles & Components\", 2520: \"Consumer Durables & Apparel\", 2530: \"Consumer Services\", 2540: \"Media\", 2550: \"Retailing\",\n",
    "    3010: \"Food & Staples Retailing\", 3020: \"Food, Beverage & Tobacco\", 3030: \"Household & Personal Products\",\n",
    "    3510: \"Health Care Equipment & Services\", 3520: \"Pharmaceuticals, Biotechnology & Life Sciences\",\n",
    "    4010: \"Banks\", 4020: \"Diversified Financials\", 4030: \"Insurance\",\n",
    "    4510: \"Software & Services\", 4520: \"Technology Hardware & Equipment\", 4530: \"Semiconductors & Semiconductor Equipment\",\n",
    "    5010: \"Telecommunication Services\", 5020: \"Media & Entertainment\",\n",
    "    5510: \"Utilities\",\n",
    "    6010: \"Real Estate\"\n",
    "}\n",
    "\n",
    "# create company mapping with names\n",
    "print(\"creating comprehensive gics mapping\")\n",
    "\n",
    "# get unique companies with sector information\n",
    "company_sectors = df[['gvkey', 'CIK', 'Ticker', 'Company Name', 'Sector', \n",
    "                     'sector_gsector', 'sector_ggroup', 'sector_gind', 'sector_gsubind']].drop_duplicates(subset=['gvkey'])\n",
    "\n",
    "# add gics names\n",
    "company_sectors['GICS_Sector_Code'] = company_sectors['sector_gsector']\n",
    "company_sectors['GICS_Sector_Name'] = company_sectors['sector_gsector'].map(gics_sector_names)\n",
    "\n",
    "company_sectors['GICS_Group_Code'] = company_sectors['sector_ggroup'] \n",
    "company_sectors['GICS_Group_Name'] = company_sectors['sector_ggroup'].map(gics_group_names)\n",
    "\n",
    "print(f\"mapped gics names for {len(company_sectors):,} companies\")\n",
    "\n",
    "# create distribution tables for each level\n",
    "\n",
    "print(\"\\ncreating distribution tables\")\n",
    "\n",
    "# sector distribution (level 1)\n",
    "sector_dist = company_sectors.groupby(['GICS_Sector_Code', 'Sector']).size().reset_index(name='Company_Count')\n",
    "sector_dist['Percentage'] = (sector_dist['Company_Count'] / sector_dist['Company_Count'].sum() * 100).round(2)\n",
    "sector_dist = sector_dist.sort_values('Company_Count', ascending=False)\n",
    "\n",
    "# industry group distribution (level 2)\n",
    "group_dist = company_sectors.groupby(['GICS_Group_Code', 'GICS_Group_Name', 'Sector']).size().reset_index(name='Company_Count')\n",
    "group_dist['Percentage'] = (group_dist['Company_Count'] / group_dist['Company_Count'].sum() * 100).round(2)\n",
    "group_dist = group_dist.sort_values('Company_Count', ascending=False)\n",
    "\n",
    "print(f\"created distribution tables:\")\n",
    "print(f\"   sectors: {len(sector_dist)} categories\")\n",
    "print(f\"   industry groups: {len(group_dist)} categories\") \n",
    "\n",
    "# create visualizations\n",
    "print(f\"\\ncreating visualizations\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# sector distribution bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "bars = plt.bar(range(len(sector_dist)), sector_dist['Company_Count'], \n",
    "               color='steelblue', alpha=0.8, edgecolor='navy', linewidth=0.5)\n",
    "\n",
    "plt.title('Company Distribution by GICS Sector\\n', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('\\nGICS Sector', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Companies\\n', fontsize=12, fontweight='bold')\n",
    "\n",
    "# set x-axis labels (use sector names)\n",
    "plt.xticks(range(len(sector_dist)), sector_dist['Sector'], rotation=45, ha='right')\n",
    "\n",
    "# add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "             f'{int(height)}\\n({sector_dist.iloc[i][\"Percentage\"]:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}gics_sector_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# industry group distribution bar chart (top 15)\n",
    "plt.figure(figsize=(16, 10))\n",
    "top_groups = group_dist.head(15)\n",
    "\n",
    "bars = plt.bar(range(len(top_groups)), top_groups['Company_Count'], \n",
    "               color='lightcoral', alpha=0.8, edgecolor='darkred', linewidth=0.5)\n",
    "\n",
    "plt.title('Company Distribution by GICS Industry Group (Top 15)\\n', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.xlabel('\\nGICS Industry Group', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Number of Companies\\n', fontsize=12, fontweight='bold')\n",
    "\n",
    "# set x-axis labels (truncate if too long)\n",
    "group_labels = [name[:25] + '...' if len(str(name)) > 25 else str(name) for name in top_groups['GICS_Group_Name']]\n",
    "plt.xticks(range(len(top_groups)), group_labels, rotation=45, ha='right')\n",
    "\n",
    "# add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{int(height)}\\n({top_groups.iloc[i][\"Percentage\"]:.1f}%)',\n",
    "             ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "\n",
    "plt.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}gics_group_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"created visualizations:\")\n",
    "print(f\"   gics_sector_distribution.png\")\n",
    "print(f\"   gics_group_distribution.png\")\n",
    "\n",
    "print(f\"\\ngics analysis complete\")\n",
    "print(f\"all files saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\ngics hierarchy overview:\")\n",
    "print(f\"   level 1 - sectors: {len(sector_dist)} categories\")\n",
    "print(f\"   level 2 - industry groups: {len(group_dist)} categories\")\n",
    "\n",
    "print(f\"\\nfiles created:\")\n",
    "print(f\"   visualizations:\")\n",
    "print(f\"      • gics_sector_distribution.png\")\n",
    "print(f\"      • gics_group_distribution.png\")\n",
    "\n",
    "print(f\"\\ntop 5 by level:\")\n",
    "print(f\"sectors: {', '.join(sector_dist.head()['Sector'].tolist())}\")\n",
    "print(f\"groups: {', '.join([str(name) for name in group_dist.head()['GICS_Group_Name'].tolist() if pd.notna(name)])}\")\n",
    "\n",
    "print(f\"\\nready for thesis appendix and methodology section\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b2e39-6f84-4a2b-bb99-282669b35d4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# load cleaned dataset\n",
    "load_path = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered.csv\"\n",
    "df = pd.read_csv(load_path)\n",
    "\n",
    "# ensure proper formatting\n",
    "df['CIK'] = df['CIK'].astype(str).str.zfill(10)\n",
    "df['gvkey'] = df['gvkey'].astype(str).str.zfill(6)\n",
    "\n",
    "# create output directory\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"ai factor summary analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"output directory: {output_dir}\")\n",
    "print(f\"dataset: {df.shape[0]:,} observations, {df['gvkey'].nunique():,} unique companies\")\n",
    "\n",
    "# define ai factor columns with numeric versions\n",
    "factor_columns = {\n",
    "    'Strategic Depth': ['Strategic Depth_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric'],\n",
    "    'Disclosure Sentiment': ['Disclosure Sentiment_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric'],\n",
    "    'Risk - Own Adoption': ['Risk - Own Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric'],\n",
    "    'Risk - External Threats': ['Risk - External Threats_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric'],\n",
    "    'Risk - Non-Adoption': ['Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric'],\n",
    "    'Forward-Looking': ['Forward-Looking_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric'],\n",
    "    'Talent & Investment': ['Talent & Investment_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric'],\n",
    "    'AI Washing Index': ['AI Washing Index_gpt4o_Numeric', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric']\n",
    "}\n",
    "\n",
    "model_names = ['GPT-4o', 'Gemini 1.5 Flash', 'Gemini 2.5 Flash']\n",
    "model_short = ['gpt4o', 'flash1_5', 'flash2_5']\n",
    "\n",
    "print(f\"analyzing {len(factor_columns)} AI factors across {len(model_names)} LLM models\")\n",
    "\n",
    "# create comprehensive factor summary\n",
    "print(\"\\ncreating factor summary statistics\")\n",
    "\n",
    "factor_summary = {}\n",
    "all_factor_stats = []\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    factor_data = []\n",
    "    \n",
    "    for i, col in enumerate(columns):\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            \n",
    "            if len(data) == 0:\n",
    "                print(f\"no data for {col}\")\n",
    "                continue\n",
    "            \n",
    "            # calculate key metrics\n",
    "            mean_val = data.mean()\n",
    "            median_val = data.median()\n",
    "            std_val = data.std()\n",
    "            min_val = data.min()\n",
    "            max_val = data.max()\n",
    "            \n",
    "            # map numeric values to letter grades (1=E, 2=D, 3=C, 4=B, 5=A)\n",
    "            grade_map = {5: 'A', 4: 'B', 3: 'C', 2: 'D', 1: 'E'}\n",
    "            median_grade = grade_map.get(int(round(median_val)), 'N/A')\n",
    "            \n",
    "            # count distribution of scores\n",
    "            score_counts = data.value_counts().sort_index(ascending=False)\n",
    "            total_scores = len(data)\n",
    "            \n",
    "            # calculate percentages for each grade\n",
    "            percentages = {}\n",
    "            for score in [5, 4, 3, 2, 1]:\n",
    "                count = score_counts.get(score, 0)\n",
    "                percentages[score] = round(count / total_scores * 100, 1) if total_scores > 0 else 0\n",
    "            \n",
    "            factor_data.append({\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Observations': int(total_scores),\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median': round(median_val, 1),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Std_Dev': round(std_val, 2),\n",
    "                'Min': int(min_val),\n",
    "                'Max': int(max_val),\n",
    "                'Grade_A_Pct': percentages.get(5, 0),\n",
    "                'Grade_B_Pct': percentages.get(4, 0),\n",
    "                'Grade_C_Pct': percentages.get(3, 0),\n",
    "                'Grade_D_Pct': percentages.get(2, 0),\n",
    "                'Grade_E_Pct': percentages.get(1, 0)\n",
    "            })\n",
    "            \n",
    "            all_factor_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Observations': int(total_scores)\n",
    "            })\n",
    "    \n",
    "    factor_summary[factor] = pd.DataFrame(factor_data)\n",
    "\n",
    "# create overall summary dataframe\n",
    "all_stats_df = pd.DataFrame(all_factor_stats)\n",
    "\n",
    "print(\"factor summary statistics created\")\n",
    "\n",
    "# print factor summaries\n",
    "print(\"\\nfactor summary by dimension\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    if not summary_df.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        display_cols = ['Model', 'Observations', 'Mean', 'Median_Grade', 'Std_Dev', 'Grade_A_Pct', 'Grade_B_Pct', 'Grade_C_Pct', 'Grade_D_Pct', 'Grade_E_Pct']\n",
    "        display_df = summary_df[display_cols].copy()\n",
    "        display_df.columns = ['Model', 'Obs', 'Mean', 'Med.Grade', 'StdDev', '%A', '%B', '%C', '%D', '%E']\n",
    "        print(display_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nai factor analysis complete\")\n",
    "print(f\"files saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\nanalysis overview:\")\n",
    "print(f\"   factors analyzed: {len(factor_columns)}\")\n",
    "print(f\"   llm models: {len(model_names)}\")\n",
    "print(f\"   total observations: {df.shape[0]:,}\")\n",
    "print(f\"   unique companies: {df['gvkey'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nready for thesis empirical analysis and methodology documentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddf215f-c132-4444-826f-ecb949b13625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ensure proper formatting\n",
    "df['CIK'] = df['CIK'].astype(str).str.zfill(10)\n",
    "df['gvkey'] = df['gvkey'].astype(str).str.zfill(6)\n",
    "\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"ai factor summary analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"output directory: {output_dir}\")\n",
    "print(f\"dataset: {df.shape[0]:,} observations, {df['gvkey'].nunique():,} unique companies\")\n",
    "\n",
    "# define ai factor columns\n",
    "factor_columns = {\n",
    "    'Strategic Depth': ['Strategic Depth_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric'],\n",
    "    'Disclosure Sentiment': ['Disclosure Sentiment_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric'],\n",
    "    'Risk - Own Adoption': ['Risk - Own Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric'],\n",
    "    'Risk - External Threats': ['Risk - External Threats_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric'],\n",
    "    'Risk - Non-Adoption': ['Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric'],\n",
    "    'Forward-Looking': ['Forward-Looking_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric'],\n",
    "    'Talent & Investment': ['Talent & Investment_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric'],\n",
    "    'AI Washing Index': ['AI Washing Index_gpt4o_Numeric', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric']\n",
    "}\n",
    "\n",
    "model_names = ['GPT-4o', 'Gemini 1.5 Flash', 'Gemini 2.5 Flash']\n",
    "model_short = ['gpt4o', 'flash1_5', 'flash2_5']\n",
    "\n",
    "print(f\"analyzing {len(factor_columns)} AI factors across {len(model_names)} LLM models\")\n",
    "\n",
    "# create comprehensive factor summary\n",
    "print(\"\\ncreating factor summary statistics\")\n",
    "\n",
    "factor_summary = {}\n",
    "all_factor_stats = []\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    factor_data = []\n",
    "    \n",
    "    for i, col in enumerate(columns):\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            \n",
    "            if len(data) == 0:\n",
    "                print(f\"no data for {col}\")\n",
    "                continue\n",
    "            \n",
    "            # calculate key metrics\n",
    "            mean_val = data.mean()\n",
    "            median_val = data.median()\n",
    "            std_val = data.std()\n",
    "            min_val = data.min()\n",
    "            max_val = data.max()\n",
    "            \n",
    "            # map numeric values to letter grades\n",
    "            grade_map = {5: 'A', 4: 'B', 3: 'C', 2: 'D', 1: 'E'}\n",
    "            median_grade = grade_map.get(int(round(median_val)), 'N/A')\n",
    "            \n",
    "            # count distribution of scores\n",
    "            score_counts = data.value_counts().sort_index(ascending=False)\n",
    "            total_scores = len(data)\n",
    "            \n",
    "            # calculate percentages for each grade\n",
    "            percentages = {}\n",
    "            for score in [5, 4, 3, 2, 1]:\n",
    "                count = score_counts.get(score, 0)\n",
    "                percentages[score] = round(count / total_scores * 100, 1) if total_scores > 0 else 0\n",
    "            \n",
    "            factor_data.append({\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Observations': int(total_scores),\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median': round(median_val, 1),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Std_Dev': round(std_val, 2),\n",
    "                'Min': int(min_val),\n",
    "                'Max': int(max_val),\n",
    "                'Grade_A_Pct': percentages.get(5, 0),\n",
    "                'Grade_B_Pct': percentages.get(4, 0),\n",
    "                'Grade_C_Pct': percentages.get(3, 0),\n",
    "                'Grade_D_Pct': percentages.get(2, 0),\n",
    "                'Grade_E_Pct': percentages.get(1, 0)\n",
    "            })\n",
    "            \n",
    "            # add to overall stats\n",
    "            all_factor_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Observations': int(total_scores)\n",
    "            })\n",
    "    \n",
    "    factor_summary[factor] = pd.DataFrame(factor_data)\n",
    "\n",
    "all_stats_df = pd.DataFrame(all_factor_stats)\n",
    "\n",
    "print(\"factor summary statistics created\")\n",
    "\n",
    "# print factor summaries\n",
    "print(\"\\nfactor summary by dimension\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    if not summary_df.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        display_cols = ['Model', 'Observations', 'Mean', 'Median_Grade', 'Std_Dev', 'Grade_A_Pct', 'Grade_B_Pct', 'Grade_C_Pct', 'Grade_D_Pct', 'Grade_E_Pct']\n",
    "        display_df = summary_df[display_cols].copy()\n",
    "        display_df.columns = ['Model', 'Obs', 'Mean', 'Med.Grade', 'StdDev', '%A', '%B', '%C', '%D', '%E']\n",
    "        print(display_df.to_string(index=False))\n",
    "\n",
    "# create visualizations\n",
    "print(f\"\\ncreating visualizations\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# factor distributions - stacked bar chart\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = ['#2E8B57', '#32CD32', '#FFD700', '#FF8C00', '#DC143C']  \n",
    "grade_labels = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "for i, (factor, summary_df) in enumerate(factor_summary.items()):\n",
    "    if i < 8 and not summary_df.empty:\n",
    "        ax = axes[i]\n",
    "        \n",
    "        models = summary_df['Model'].tolist()\n",
    "        grade_data = []\n",
    "        \n",
    "        for grade_col in ['Grade_A_Pct', 'Grade_B_Pct', 'Grade_C_Pct', 'Grade_D_Pct', 'Grade_E_Pct']:\n",
    "            grade_data.append(summary_df[grade_col].tolist())\n",
    "        \n",
    "        bottom = np.zeros(len(models))\n",
    "        bars = []\n",
    "        \n",
    "        for j, (grade_pct, color, label) in enumerate(zip(grade_data, colors, grade_labels)):\n",
    "            bars.append(ax.bar(models, grade_pct, bottom=bottom, color=color, label=f'Grade {label}', alpha=0.8))\n",
    "            bottom += grade_pct\n",
    "        \n",
    "        ax.set_title(f'{factor}', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Percentage', fontsize=9)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # add percentage labels for A and B grades\n",
    "        for j, model_idx in enumerate(range(len(models))):\n",
    "            if grade_data[0][model_idx] > 5:\n",
    "                ax.text(model_idx, grade_data[0][model_idx]/2, f'{grade_data[0][model_idx]:.0f}%', \n",
    "                       ha='center', va='center', fontsize=7, fontweight='bold', color='white')\n",
    "            \n",
    "            if grade_data[1][model_idx] > 5:\n",
    "                y_pos = grade_data[0][model_idx] + grade_data[1][model_idx]/2\n",
    "                ax.text(model_idx, y_pos, f'{grade_data[1][model_idx]:.0f}%', \n",
    "                       ha='center', va='center', fontsize=7, fontweight='bold', color='white')\n",
    "\n",
    "if len(factor_summary) > 0:\n",
    "    axes[7].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "\n",
    "for i in range(len(factor_summary), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.suptitle('AI Factor Distributions Across LLM Models', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# model comparison heatmap\n",
    "print(\"creating model comparison heatmap...\")\n",
    "\n",
    "heatmap_data = []\n",
    "factor_names = []\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    if not summary_df.empty:\n",
    "        factor_names.append(factor)\n",
    "        row_data = []\n",
    "        for model_code in model_short:\n",
    "            model_data = summary_df[summary_df['Model_Code'] == model_code]\n",
    "            if not model_data.empty:\n",
    "                grade_to_num = {'A': 5, 'B': 4, 'C': 3, 'D': 2, 'E': 1}\n",
    "                median_grade = model_data['Median_Grade'].iloc[0]\n",
    "                row_data.append(grade_to_num.get(median_grade, 3))\n",
    "            else:\n",
    "                row_data.append(3)\n",
    "        heatmap_data.append(row_data)\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_data, columns=model_names, index=factor_names)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='RdYlGn', center=3, \n",
    "            cbar_kws={'label': 'Grade (1=E, 5=A)'}, fmt='.1f',\n",
    "            linewidths=0.5)\n",
    "plt.title('AI Factor Median Grades by Model', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('LLM Model', fontsize=12)\n",
    "plt.ylabel('AI Factor', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# overall grade distribution  \n",
    "print(\"creating overall grade distribution...\")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "all_grades = []\n",
    "all_models = []\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    for _, row in summary_df.iterrows():\n",
    "        for grade, pct in zip(['A', 'B', 'C', 'D', 'E'], \n",
    "                             [row['Grade_A_Pct'], row['Grade_B_Pct'], row['Grade_C_Pct'], \n",
    "                              row['Grade_D_Pct'], row['Grade_E_Pct']]):\n",
    "            all_grades.extend([grade] * int(pct))\n",
    "            all_models.extend([row['Model']] * int(pct))\n",
    "\n",
    "grade_dist_df = pd.DataFrame({'Grade': all_grades, 'Model': all_models})\n",
    "\n",
    "sns.countplot(data=grade_dist_df, x='Grade', hue='Model', palette='viridis')\n",
    "plt.title('Overall Grade Distribution Across All AI Factors', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Grade', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='LLM Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_overall_grades.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"created visualizations:\")\n",
    "print(f\"   ai_factor_distributions.png\")\n",
    "print(f\"   ai_factor_model_comparison.png\")\n",
    "print(f\"   ai_factor_overall_grades.png\")\n",
    "\n",
    "print(f\"\\nai factor analysis complete!\")\n",
    "print(f\"all files saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\nanalysis overview:\")\n",
    "print(f\"   factors analyzed: {len(factor_columns)}\")\n",
    "print(f\"   llm models: {len(model_names)}\")\n",
    "print(f\"   total observations: {df.shape[0]:,}\")\n",
    "print(f\"   unique companies: {df['gvkey'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nperfect for thesis empirical analysis and methodology documentation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0f6d4-f2fa-4638-a7d2-6668890bbe16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# ensure proper formatting\n",
    "df['CIK'] = df['CIK'].astype(str).str.zfill(10)\n",
    "df['gvkey'] = df['gvkey'].astype(str).str.zfill(6)\n",
    "\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"ai factor summary analysis\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"output directory: {output_dir}\")\n",
    "print(f\"dataset: {df.shape[0]:,} observations, {df['gvkey'].nunique():,} unique companies\")\n",
    "\n",
    "# define ai factor columns\n",
    "factor_columns = {\n",
    "    'Strategic Depth': ['Strategic Depth_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric'],\n",
    "    'Disclosure Sentiment': ['Disclosure Sentiment_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric'],\n",
    "    'Risk - Own Adoption': ['Risk - Own Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric'],\n",
    "    'Risk - External Threats': ['Risk - External Threats_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric'],\n",
    "    'Risk - Non-Adoption': ['Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric'],\n",
    "    'Forward-Looking': ['Forward-Looking_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric'],\n",
    "    'Talent & Investment': ['Talent & Investment_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric'],\n",
    "    'AI Washing Index': ['AI Washing Index_gpt4o_Numeric', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric']\n",
    "}\n",
    "\n",
    "model_names = ['GPT-4o', 'Gemini 1.5 Flash', 'Gemini 2.5 Flash']\n",
    "model_short = ['gpt4o', 'flash1_5', 'flash2_5']\n",
    "\n",
    "print(f\"analyzing {len(factor_columns)} AI factors across {len(model_names)} LLM models\")\n",
    "\n",
    "# create comprehensive factor summary\n",
    "print(\"\\ncreating factor summary statistics\")\n",
    "\n",
    "factor_summary = {}\n",
    "all_factor_stats = []\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    factor_data = []\n",
    "    \n",
    "    for i, col in enumerate(columns):\n",
    "        if col in df.columns:\n",
    "            data = df[col].dropna()\n",
    "            \n",
    "            if len(data) == 0:\n",
    "                print(f\"no data for {col}\")\n",
    "                continue\n",
    "            \n",
    "            # calculate key metrics\n",
    "            mean_val = data.mean()\n",
    "            median_val = data.median()\n",
    "            std_val = data.std()\n",
    "            min_val = data.min()\n",
    "            max_val = data.max()\n",
    "            \n",
    "            # map numeric values to letter grades\n",
    "            grade_map = {5: 'A', 4: 'B', 3: 'C', 2: 'D', 1: 'E'}\n",
    "            median_grade = grade_map.get(int(round(median_val)), 'N/A')\n",
    "            \n",
    "            # count distribution of scores\n",
    "            score_counts = data.value_counts().sort_index(ascending=False)\n",
    "            total_scores = len(data)\n",
    "            \n",
    "            # calculate percentages for each grade\n",
    "            percentages = {}\n",
    "            for score in [5, 4, 3, 2, 1]:\n",
    "                count = score_counts.get(score, 0)\n",
    "                percentages[score] = round(count / total_scores * 100, 1) if total_scores > 0 else 0\n",
    "            \n",
    "            factor_data.append({\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Observations': int(total_scores),\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median': round(median_val, 1),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Std_Dev': round(std_val, 2),\n",
    "                'Min': int(min_val),\n",
    "                'Max': int(max_val),\n",
    "                'Grade_A_Pct': percentages.get(5, 0),\n",
    "                'Grade_B_Pct': percentages.get(4, 0),\n",
    "                'Grade_C_Pct': percentages.get(3, 0),\n",
    "                'Grade_D_Pct': percentages.get(2, 0),\n",
    "                'Grade_E_Pct': percentages.get(1, 0)\n",
    "            })\n",
    "            \n",
    "            # add to overall stats\n",
    "            all_factor_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model': model_names[i],\n",
    "                'Model_Code': model_short[i],\n",
    "                'Mean': round(mean_val, 2),\n",
    "                'Median_Grade': median_grade,\n",
    "                'Observations': int(total_scores)\n",
    "            })\n",
    "    \n",
    "    factor_summary[factor] = pd.DataFrame(factor_data)\n",
    "\n",
    "all_stats_df = pd.DataFrame(all_factor_stats)\n",
    "\n",
    "print(\"factor summary statistics created\")\n",
    "\n",
    "# print factor summaries  \n",
    "print(\"\\nfactor summary by dimension\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    if not summary_df.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        display_cols = ['Model', 'Observations', 'Mean', 'Median_Grade', 'Std_Dev', 'Grade_A_Pct', 'Grade_B_Pct', 'Grade_C_Pct', 'Grade_D_Pct', 'Grade_E_Pct']\n",
    "        display_df = summary_df[display_cols].copy()\n",
    "        display_df.columns = ['Model', 'Obs', 'Mean', 'Med.Grade', 'StdDev', '%A', '%B', '%C', '%D', '%E']\n",
    "        print(display_df.to_string(index=False))\n",
    "\n",
    "# create visualizations\n",
    "print(f\"\\ncreating visualizations\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# factor distributions - stacked bar chart\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = ['#2E8B57', '#32CD32', '#FFD700', '#FF8C00', '#DC143C']  \n",
    "grade_labels = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "for i, (factor, summary_df) in enumerate(factor_summary.items()):\n",
    "    if i < 8 and not summary_df.empty:\n",
    "        ax = axes[i]\n",
    "        \n",
    "        models = summary_df['Model'].tolist()\n",
    "        grade_data = []\n",
    "        \n",
    "        for grade_col in ['Grade_A_Pct', 'Grade_B_Pct', 'Grade_C_Pct', 'Grade_D_Pct', 'Grade_E_Pct']:\n",
    "            grade_data.append(summary_df[grade_col].tolist())\n",
    "        \n",
    "        bottom = np.zeros(len(models))\n",
    "        bars = []\n",
    "        \n",
    "        for j, (grade_pct, color, label) in enumerate(zip(grade_data, colors, grade_labels)):\n",
    "            bars.append(ax.bar(models, grade_pct, bottom=bottom, color=color, label=f'Grade {label}', alpha=0.8))\n",
    "            bottom += grade_pct\n",
    "        \n",
    "        ax.set_title(f'{factor}', fontsize=11, fontweight='bold')\n",
    "        ax.set_ylabel('Percentage', fontsize=9)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=8)\n",
    "        ax.tick_params(axis='y', labelsize=8)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # add percentage labels for A and B grades\n",
    "        for j, model_idx in enumerate(range(len(models))):\n",
    "            if grade_data[0][model_idx] > 5:\n",
    "                ax.text(model_idx, grade_data[0][model_idx]/2, f'{grade_data[0][model_idx]:.0f}%', \n",
    "                       ha='center', va='center', fontsize=7, fontweight='bold', color='white')\n",
    "            \n",
    "            if grade_data[1][model_idx] > 5:\n",
    "                y_pos = grade_data[0][model_idx] + grade_data[1][model_idx]/2\n",
    "                ax.text(model_idx, y_pos, f'{grade_data[1][model_idx]:.0f}%', \n",
    "                       ha='center', va='center', fontsize=7, fontweight='bold', color='white')\n",
    "\n",
    "if len(factor_summary) > 0:\n",
    "    axes[7].legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)\n",
    "\n",
    "for i in range(len(factor_summary), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.suptitle('AI Factor Distributions Across LLM Models', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# model comparison heatmap\n",
    "print(\"creating model comparison heatmap...\")\n",
    "\n",
    "heatmap_data = []\n",
    "factor_names = []\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    if not summary_df.empty:\n",
    "        factor_names.append(factor)\n",
    "        row_data = []\n",
    "        for model_code in model_short:\n",
    "            model_data = summary_df[summary_df['Model_Code'] == model_code]\n",
    "            if not model_data.empty:\n",
    "                grade_to_num = {'A': 5, 'B': 4, 'C': 3, 'D': 2, 'E': 1}\n",
    "                median_grade = model_data['Median_Grade'].iloc[0]\n",
    "                row_data.append(grade_to_num.get(median_grade, 3))\n",
    "            else:\n",
    "                row_data.append(3)\n",
    "        heatmap_data.append(row_data)\n",
    "\n",
    "heatmap_df = pd.DataFrame(heatmap_data, columns=model_names, index=factor_names)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(heatmap_df, annot=True, cmap='RdYlGn', center=3, \n",
    "            cbar_kws={'label': 'Grade (1=E, 5=A)'}, fmt='.1f',\n",
    "            linewidths=0.5)\n",
    "plt.title('AI Factor Median Grades by Model', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('LLM Model', fontsize=12)\n",
    "plt.ylabel('AI Factor', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# overall grade distribution  \n",
    "print(\"creating overall grade distribution...\")\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "all_grades = []\n",
    "all_models = []\n",
    "\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    for _, row in summary_df.iterrows():\n",
    "        for grade, pct in zip(['A', 'B', 'C', 'D', 'E'], \n",
    "                             [row['Grade_A_Pct'], row['Grade_B_Pct'], row['Grade_C_Pct'], \n",
    "                              row['Grade_D_Pct'], row['Grade_E_Pct']]):\n",
    "            all_grades.extend([grade] * int(pct))\n",
    "            all_models.extend([row['Model']] * int(pct))\n",
    "\n",
    "grade_dist_df = pd.DataFrame({'Grade': all_grades, 'Model': all_models})\n",
    "\n",
    "sns.countplot(data=grade_dist_df, x='Grade', hue='Model', palette='viridis')\n",
    "plt.title('Overall Grade Distribution Across All AI Factors', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Grade', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend(title='LLM Model', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_factor_overall_grades.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# create summary tables\n",
    "print(f\"\\ncreating summary tables\")\n",
    "\n",
    "# factor summary table\n",
    "factor_summary_table = []\n",
    "for factor, summary_df in factor_summary.items():\n",
    "    for _, row in summary_df.iterrows():\n",
    "        factor_summary_table.append({\n",
    "            'Factor': factor,\n",
    "            'Model': row['Model'],\n",
    "            'Observations': row['Observations'],\n",
    "            'Mean_Score': row['Mean'],\n",
    "            'Median_Grade': row['Median_Grade'],\n",
    "            'Std_Dev': row['Std_Dev'],\n",
    "            'Pct_Grade_A': row['Grade_A_Pct'],\n",
    "            'Pct_Grade_B': row['Grade_B_Pct'],\n",
    "            'Pct_Grade_C': row['Grade_C_Pct'],\n",
    "            'Pct_High_Quality': row['Grade_A_Pct'] + row['Grade_B_Pct']\n",
    "        })\n",
    "\n",
    "factor_summary_final = pd.DataFrame(factor_summary_table)\n",
    "\n",
    "# model comparison table\n",
    "model_comparison = []\n",
    "for model_idx, model_name in enumerate(model_names):\n",
    "    model_data = factor_summary_final[factor_summary_final['Model'] == model_name]\n",
    "    \n",
    "    if not model_data.empty:\n",
    "        model_comparison.append({\n",
    "            'Model': model_name,\n",
    "            'Avg_Mean_Score': round(model_data['Mean_Score'].mean(), 2),\n",
    "            'Avg_Pct_Grade_A': round(model_data['Pct_Grade_A'].mean(), 1),\n",
    "            'Avg_Pct_Grade_B': round(model_data['Pct_Grade_B'].mean(), 1),\n",
    "            'Avg_Pct_High_Quality': round(model_data['Pct_High_Quality'].mean(), 1),\n",
    "            'Most_Common_Grade': model_data['Median_Grade'].mode().iloc[0] if len(model_data['Median_Grade'].mode()) > 0 else 'C',\n",
    "            'Total_Observations': int(model_data['Observations'].sum())\n",
    "        })\n",
    "\n",
    "model_comparison_df = pd.DataFrame(model_comparison)\n",
    "\n",
    "print(f\"summary tables prepared for word document\")\n",
    "\n",
    "# year-over-year analysis\n",
    "print(f\"\\nanalyzing ai factor evolution over time\")\n",
    "\n",
    "yearly_analysis = {}\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    gpt4o_col = columns[0]\n",
    "    if gpt4o_col in df.columns:\n",
    "        yearly_data = []\n",
    "        \n",
    "        for year in sorted(df['Year'].unique()):\n",
    "            year_data = df[df['Year'] == year][gpt4o_col].dropna()\n",
    "            \n",
    "            if len(year_data) > 0:\n",
    "                grade_counts = year_data.value_counts().sort_index(ascending=False)\n",
    "                total = len(year_data)\n",
    "                \n",
    "                grade_pcts = {}\n",
    "                for grade in [5, 4, 3, 2, 1]:\n",
    "                    grade_pcts[grade] = (grade_counts.get(grade, 0) / total * 100) if total > 0 else 0\n",
    "                \n",
    "                yearly_data.append({\n",
    "                    'Year': year,\n",
    "                    'Mean_Score': round(year_data.mean(), 2),\n",
    "                    'Median_Score': round(year_data.median(), 1),\n",
    "                    'Observations': int(total),\n",
    "                    'Pct_Grade_A': round(grade_pcts[5], 1),\n",
    "                    'Pct_Grade_B': round(grade_pcts[4], 1),\n",
    "                    'Pct_Grade_C': round(grade_pcts[3], 1),\n",
    "                    'Pct_High_Quality': round(grade_pcts[5] + grade_pcts[4], 1)\n",
    "                })\n",
    "        \n",
    "        yearly_analysis[factor] = pd.DataFrame(yearly_data)\n",
    "\n",
    "print(f\"year-over-year analysis created for {len(yearly_analysis)} factors\")\n",
    "\n",
    "print(\"creating ai evolution over time analysis...\")\n",
    "\n",
    "# mean scores over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "for factor, yearly_df in yearly_analysis.items():\n",
    "    if not yearly_df.empty and len(yearly_df) > 1:\n",
    "        plt.plot(yearly_df['Year'], yearly_df['Mean_Score'], marker='o', \n",
    "                linewidth=3, markersize=8, label=factor, alpha=0.8)\n",
    "\n",
    "plt.title('AI Factor Mean Scores Evolution (2020-2024)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Mean Score (1-5)', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.ylim(1, 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_mean_scores_evolution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# high-quality percentage over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "for factor, yearly_df in yearly_analysis.items():\n",
    "    if not yearly_df.empty and len(yearly_df) > 1:\n",
    "        plt.plot(yearly_df['Year'], yearly_df['Pct_High_Quality'], marker='s', \n",
    "                linewidth=3, markersize=8, label=factor, alpha=0.8)\n",
    "\n",
    "plt.title('High-Quality AI Disclosures Evolution - Grade A + B %', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Percentage (%)', fontsize=12, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}ai_high_quality_evolution.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# overall average across all factors\n",
    "all_years_summary = []\n",
    "years = sorted(df['Year'].unique())\n",
    "\n",
    "for year in years:\n",
    "    year_means = []\n",
    "    year_high_quality = []\n",
    "    \n",
    "    for factor, yearly_df in yearly_analysis.items():\n",
    "        year_data = yearly_df[yearly_df['Year'] == year]\n",
    "        if not year_data.empty:\n",
    "            year_means.append(year_data['Mean_Score'].iloc[0])\n",
    "            year_high_quality.append(year_data['Pct_High_Quality'].iloc[0])\n",
    "    \n",
    "    if year_means:\n",
    "        all_years_summary.append({\n",
    "            'Year': year,\n",
    "            'Avg_Mean_Score': np.mean(year_means),\n",
    "            'Avg_High_Quality': np.mean(year_high_quality)\n",
    "        })\n",
    "\n",
    "if all_years_summary:\n",
    "    summary_df = pd.DataFrame(all_years_summary)\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    line1 = ax1.plot(summary_df['Year'], summary_df['Avg_Mean_Score'], \n",
    "                     color='steelblue', marker='o', linewidth=4, markersize=10, \n",
    "                     label='Average Score')\n",
    "    line2 = ax2.plot(summary_df['Year'], summary_df['Avg_High_Quality'], \n",
    "                     color='darkred', marker='s', linewidth=4, markersize=10, \n",
    "                     label='% High Quality')\n",
    "    \n",
    "    ax1.set_title('Overall AI Disclosure Quality Evolution (2020-2024)', fontsize=16, fontweight='bold')\n",
    "    ax1.set_xlabel('Year', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Average Score (1-5)', color='steelblue', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('% High Quality (A+B)', color='darkred', fontsize=12, fontweight='bold')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_ylim(1, 5)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}ai_overall_quality_evolution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"created individual temporal analysis visualizations:\")\n",
    "print(f\"   ai_mean_scores_evolution.png\")\n",
    "print(f\"   ai_high_quality_evolution.png\") \n",
    "print(f\"   ai_overall_quality_evolution.png\")\n",
    "\n",
    "print(f\"\\nai factor analysis complete!\")\n",
    "print(f\"all files saved to: {output_dir}\")\n",
    "\n",
    "print(f\"\\nanalysis overview:\")\n",
    "print(f\"   factors analyzed: {len(factor_columns)}\")\n",
    "print(f\"   llm models: {len(model_names)}\")\n",
    "print(f\"   total observations: {df.shape[0]:,}\")\n",
    "print(f\"   unique companies: {df['gvkey'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nfiles created:\")\n",
    "print(f\"   core visualizations:\")\n",
    "print(f\"      • ai_factor_distributions.png - grade distributions by factor\")\n",
    "print(f\"      • ai_factor_model_comparison.png - model comparison heatmap\")\n",
    "print(f\"      • ai_factor_overall_grades.png - overall grade distribution\")\n",
    "print(f\"   evolution analysis:\")\n",
    "print(f\"      • ai_mean_scores_evolution.png - mean scores over time\")\n",
    "print(f\"      • ai_high_quality_evolution.png - high quality trends\")\n",
    "print(f\"      • ai_overall_quality_evolution.png - overall quality evolution\")\n",
    "\n",
    "print(f\"\\nmodel performance highlights:\")\n",
    "for _, row in model_comparison_df.iterrows():\n",
    "    print(f\"   {row['Model']:20}: avg score {row['Avg_Mean_Score']:.1f}/5.0, {row['Avg_Pct_High_Quality']:.1f}% A+B grades\")\n",
    "\n",
    "print(f\"\\nperfect for thesis empirical analysis and methodology documentation!\")\n",
    "print(f\"ready to proceed with factor-based return prediction models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d66c651-9933-47d4-945e-cd47c439966f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"inter-model agreement analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# define factor columns\n",
    "factor_columns = {\n",
    "    'Strategic Depth': ['Strategic Depth_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric'],\n",
    "    'Disclosure Sentiment': ['Disclosure Sentiment_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric'],\n",
    "    'Risk - Own Adoption': ['Risk - Own Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric'],\n",
    "    'Risk - External Threats': ['Risk - External Threats_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric'],\n",
    "    'Risk - Non-Adoption': ['Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric'],\n",
    "    'Forward-Looking': ['Forward-Looking_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric'],\n",
    "    'Talent & Investment': ['Talent & Investment_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric'],\n",
    "    'AI Washing Index': ['AI Washing Index_gpt4o_Numeric', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric']\n",
    "}\n",
    "\n",
    "# calculate inter-model agreement for each factor\n",
    "agreement_stats = {}\n",
    "overall_stats = []\n",
    "\n",
    "print(\"calculating inter-model agreement statistics...\")\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    if len(columns) == 3 and all(col in df.columns for col in columns):\n",
    "        # get data with all three models having valid values\n",
    "        valid_data = df[columns].dropna()\n",
    "        n_valid = len(valid_data)\n",
    "        \n",
    "        if n_valid == 0:\n",
    "            print(f\"no valid data for {factor}\")\n",
    "            continue\n",
    "        \n",
    "        # exact match percentages\n",
    "        gpt_vs_gem15 = (valid_data[columns[0]] == valid_data[columns[1]]).mean() * 100\n",
    "        gpt_vs_gem25 = (valid_data[columns[0]] == valid_data[columns[2]]).mean() * 100\n",
    "        gem15_vs_gem25 = (valid_data[columns[1]] == valid_data[columns[2]]).mean() * 100\n",
    "        \n",
    "        # within 1 grade percentages\n",
    "        gpt_vs_gem15_within1 = (abs(valid_data[columns[0]] - valid_data[columns[1]]) <= 1).mean() * 100\n",
    "        gpt_vs_gem25_within1 = (abs(valid_data[columns[0]] - valid_data[columns[2]]) <= 1).mean() * 100\n",
    "        gem15_vs_gem25_within1 = (abs(valid_data[columns[1]] - valid_data[columns[2]]) <= 1).mean() * 100\n",
    "        \n",
    "        # calculate correlations\n",
    "        corr_gpt_gem15 = valid_data[columns[0]].corr(valid_data[columns[1]])\n",
    "        corr_gpt_gem25 = valid_data[columns[0]].corr(valid_data[columns[2]])\n",
    "        corr_gem15_gem25 = valid_data[columns[1]].corr(valid_data[columns[2]])\n",
    "        \n",
    "        agreement_stats[factor] = {\n",
    "            'GPT-4o vs Gemini 1.5': {\n",
    "                '% Exact Match': round(gpt_vs_gem15, 1),\n",
    "                '% Within 1 Grade': round(gpt_vs_gem15_within1, 1),\n",
    "                'Correlation': round(corr_gpt_gem15, 3)\n",
    "            },\n",
    "            'GPT-4o vs Gemini 2.5': {\n",
    "                '% Exact Match': round(gpt_vs_gem25, 1),\n",
    "                '% Within 1 Grade': round(gpt_vs_gem25_within1, 1),\n",
    "                'Correlation': round(corr_gpt_gem25, 3)\n",
    "            },\n",
    "            'Gemini 1.5 vs Gemini 2.5': {\n",
    "                '% Exact Match': round(gem15_vs_gem25, 1),\n",
    "                '% Within 1 Grade': round(gem15_vs_gem25_within1, 1),\n",
    "                'Correlation': round(corr_gem15_gem25, 3)\n",
    "            },\n",
    "            'Valid Observations': n_valid\n",
    "        }\n",
    "        \n",
    "        # add to overall stats\n",
    "        overall_stats.extend([\n",
    "            {'Factor': factor, 'Comparison': 'GPT-4o vs Gemini 1.5', 'Exact_Match': gpt_vs_gem15, 'Within_1': gpt_vs_gem15_within1, 'Correlation': corr_gpt_gem15},\n",
    "            {'Factor': factor, 'Comparison': 'GPT-4o vs Gemini 2.5', 'Exact_Match': gpt_vs_gem25, 'Within_1': gpt_vs_gem25_within1, 'Correlation': corr_gpt_gem25},\n",
    "            {'Factor': factor, 'Comparison': 'Gemini 1.5 vs Gemini 2.5', 'Exact_Match': gem15_vs_gem25, 'Within_1': gem15_vs_gem25_within1, 'Correlation': corr_gem15_gem25}\n",
    "        ])\n",
    "\n",
    "# create a dataframe for easy visualization\n",
    "agreement_rows = []\n",
    "for factor, stats in agreement_stats.items():\n",
    "    for comparison, values in stats.items():\n",
    "        if comparison != 'Valid Observations':\n",
    "            agreement_rows.append({\n",
    "                'Factor': factor,\n",
    "                'Model Comparison': comparison,\n",
    "                'Exact Match %': values['% Exact Match'],\n",
    "                'Within 1 Grade %': values['% Within 1 Grade'],\n",
    "                'Correlation': values['Correlation']\n",
    "            })\n",
    "\n",
    "agreement_df = pd.DataFrame(agreement_rows)\n",
    "\n",
    "# print agreement statistics\n",
    "print(\"\\ninter-model agreement statistics:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor in factor_columns.keys():\n",
    "    if factor in agreement_stats:\n",
    "        factor_data = agreement_df[agreement_df['Factor'] == factor]\n",
    "        if not factor_data.empty:\n",
    "            print(f\"\\n{factor}:\")\n",
    "            print(f\"   valid observations: {agreement_stats[factor]['Valid Observations']:,}\")\n",
    "            for _, row in factor_data.iterrows():\n",
    "                print(f\"   {row['Model Comparison']:20}: exact={row['Exact Match %']:5.1f}%, within1={row['Within 1 Grade %']:5.1f}%, corr={row['Correlation']:5.3f}\")\n",
    "\n",
    "# calculate overall statistics\n",
    "if overall_stats:\n",
    "    overall_df = pd.DataFrame(overall_stats)\n",
    "    print(f\"\\noverall agreement summary:\")\n",
    "    print(f\"   average exact match: {overall_df['Exact_Match'].mean():.1f}%\")\n",
    "    print(f\"   average within 1 grade: {overall_df['Within_1'].mean():.1f}%\") \n",
    "    print(f\"   average correlation: {overall_df['Correlation'].mean():.3f}\")\n",
    "\n",
    "# create visualizations\n",
    "print(f\"\\ncreating agreement visualizations...\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# exact match heatmap\n",
    "if not agreement_df.empty:\n",
    "    agreement_pivot = agreement_df.pivot_table(\n",
    "        index='Factor', \n",
    "        columns='Model Comparison', \n",
    "        values='Exact Match %'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(agreement_pivot, annot=True, cmap='YlGnBu', fmt='.1f', \n",
    "                vmin=0, vmax=100, cbar_kws={'label': 'Exact Match %'})\n",
    "    plt.title('Exact Match Agreement Between LLM Models\\nAI Factor Assessment', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Model Comparison', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('AI Factor', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}model_agreement_exact_match.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# within 1 grade heatmap\n",
    "if not agreement_df.empty:\n",
    "    within1_pivot = agreement_df.pivot_table(\n",
    "        index='Factor', \n",
    "        columns='Model Comparison', \n",
    "        values='Within 1 Grade %'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(within1_pivot, annot=True, cmap='RdYlGn', fmt='.1f', \n",
    "                vmin=0, vmax=100, cbar_kws={'label': 'Within 1 Grade %'})\n",
    "    plt.title('Agreement Within 1 Grade Between LLM Models\\nAI Factor Assessment', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Model Comparison', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('AI Factor', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}model_agreement_within1_grade.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# correlation heatmap\n",
    "if not agreement_df.empty:\n",
    "    correlation_pivot = agreement_df.pivot_table(\n",
    "        index='Factor', \n",
    "        columns='Model Comparison', \n",
    "        values='Correlation'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(correlation_pivot, annot=True, cmap='coolwarm', fmt='.3f', \n",
    "                vmin=0, vmax=1, center=0.5, cbar_kws={'label': 'Correlation'})\n",
    "    plt.title('Correlation Between LLM Model Assessments\\nAI Factor Scores', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.xlabel('Model Comparison', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('AI Factor', fontsize=12, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}model_agreement_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# summary bar chart\n",
    "if overall_stats:\n",
    "    # create summary by comparison type\n",
    "    comparison_summary = overall_df.groupby('Comparison').agg({\n",
    "        'Exact_Match': 'mean',\n",
    "        'Within_1': 'mean', \n",
    "        'Correlation': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 6))\n",
    "    \n",
    "    # exact match\n",
    "    bars1 = ax1.bar(range(len(comparison_summary)), comparison_summary['Exact_Match'], \n",
    "                   color='steelblue', alpha=0.8)\n",
    "    ax1.set_title('Average Exact Match %', fontweight='bold')\n",
    "    ax1.set_ylabel('Percentage')\n",
    "    ax1.set_xticks(range(len(comparison_summary)))\n",
    "    ax1.set_xticklabels([comp.replace(' vs ', '\\nvs\\n') for comp in comparison_summary['Comparison']], \n",
    "                       fontsize=9)\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # add value labels\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # within 1 grade\n",
    "    bars2 = ax2.bar(range(len(comparison_summary)), comparison_summary['Within_1'], \n",
    "                   color='darkgreen', alpha=0.8)\n",
    "    ax2.set_title('Average Within 1 Grade %', fontweight='bold')\n",
    "    ax2.set_ylabel('Percentage')\n",
    "    ax2.set_xticks(range(len(comparison_summary)))\n",
    "    ax2.set_xticklabels([comp.replace(' vs ', '\\nvs\\n') for comp in comparison_summary['Comparison']], \n",
    "                       fontsize=9)\n",
    "    ax2.set_ylim(0, 100)\n",
    "    \n",
    "    # add value labels\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # correlations\n",
    "    bars3 = ax3.bar(range(len(comparison_summary)), comparison_summary['Correlation'], \n",
    "                   color='darkred', alpha=0.8)\n",
    "    ax3.set_title('Average Correlation', fontweight='bold')\n",
    "    ax3.set_ylabel('Correlation')\n",
    "    ax3.set_xticks(range(len(comparison_summary)))\n",
    "    ax3.set_xticklabels([comp.replace(' vs ', '\\nvs\\n') for comp in comparison_summary['Comparison']], \n",
    "                       fontsize=9)\n",
    "    ax3.set_ylim(0, 1)\n",
    "    \n",
    "    # add value labels\n",
    "    for bar in bars3:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Inter-Model Agreement Summary\\nAcross All AI Factors', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_dir}model_agreement_summary.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(f\"agreement analysis visualizations created:\")\n",
    "print(f\"   model_agreement_exact_match.png\")\n",
    "print(f\"   model_agreement_within1_grade.png\")\n",
    "print(f\"   model_agreement_correlations.png\")\n",
    "print(f\"   model_agreement_summary.png\")\n",
    "\n",
    "print(f\"\\ninter-model agreement analysis complete!\")\n",
    "print(f\"all files saved to: {output_dir}\")\n",
    "\n",
    "if overall_stats:\n",
    "    print(f\"\\nkey findings:\")\n",
    "    print(f\"   average exact match: {overall_df['Exact_Match'].mean():.1f}%\")\n",
    "    print(f\"   average within 1 grade: {overall_df['Within_1'].mean():.1f}%\")\n",
    "    print(f\"   average correlation: {overall_df['Correlation'].mean():.3f}\")\n",
    "    \n",
    "    # identify best and worst agreement\n",
    "    best_factor = overall_df.groupby('Factor')['Correlation'].mean().idxmax()\n",
    "    worst_factor = overall_df.groupby('Factor')['Correlation'].mean().idxmin()\n",
    "    \n",
    "    print(f\"\\nfactor with highest agreement: {best_factor}\")\n",
    "    print(f\"factor with lowest agreement: {worst_factor}\")\n",
    "\n",
    "print(f\"\\nfiles created:\")\n",
    "print(f\"   visualizations:\")\n",
    "print(f\"      • model_agreement_exact_match.png\")\n",
    "print(f\"      • model_agreement_within1_grade.png\") \n",
    "print(f\"      • model_agreement_correlations.png\")\n",
    "print(f\"      • model_agreement_summary.png\")\n",
    "\n",
    "print(f\"\\nperfect for thesis methodology section on measurement robustness!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8624550a-01d7-43da-95e0-afbf3b5ee1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import os\n",
    "\n",
    "output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/SummaryStats/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"enhanced inter-model correlation analysis\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# define factor columns with numeric versions\n",
    "factor_columns = {\n",
    "    'Strategic Depth': ['Strategic Depth_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric'],\n",
    "    'Disclosure Sentiment': ['Disclosure Sentiment_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric'],\n",
    "    'Risk - Own Adoption': ['Risk - Own Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric'],\n",
    "    'Risk - External Threats': ['Risk - External Threats_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric'],\n",
    "    'Risk - Non-Adoption': ['Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric'],\n",
    "    'Forward-Looking': ['Forward-Looking_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric'],\n",
    "    'Talent & Investment': ['Talent & Investment_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric'],\n",
    "    'AI Washing Index': ['AI Washing Index_gpt4o_Numeric', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric']\n",
    "}\n",
    "\n",
    "model_names = ['GPT-4o mini', 'Gemini 1.5 Flash', 'Gemini 2.5 Flash']\n",
    "model_pairs = [\n",
    "    ('GPT-4o mini', 'Gemini 1.5 Flash'),\n",
    "    ('GPT-4o mini', 'Gemini 2.5 Flash'),\n",
    "    ('Gemini 1.5 Flash', 'Gemini 2.5 Flash')\n",
    "]\n",
    "\n",
    "print(f\"analyzing {len(factor_columns)} factors across {len(model_names)} models\")\n",
    "\n",
    "# comprehensive correlation and agreement analysis\n",
    "print(\"\\ncalculating comprehensive correlation and agreement metrics...\")\n",
    "\n",
    "correlation_stats = []\n",
    "agreement_stats = []\n",
    "kappa_stats = []\n",
    "\n",
    "def weighted_kappa_ordinal(y1, y2):\n",
    "    \"\"\"calculate weighted cohen's kappa for ordinal data - uses quadratic weights\"\"\"\n",
    "    try:\n",
    "        mask = ~(pd.isna(y1) | pd.isna(y2))\n",
    "        y1_clean = y1[mask]\n",
    "        y2_clean = y2[mask]\n",
    "        \n",
    "        if len(y1_clean) == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        return cohen_kappa_score(y1_clean, y2_clean, weights='quadratic')\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def linear_kappa_ordinal(y1, y2):\n",
    "    \"\"\"calculate linearly weighted cohen's kappa for ordinal data\"\"\"\n",
    "    try:\n",
    "        mask = ~(pd.isna(y1) | pd.isna(y2))\n",
    "        y1_clean = y1[mask]\n",
    "        y2_clean = y2[mask]\n",
    "        \n",
    "        if len(y1_clean) == 0:\n",
    "            return np.nan\n",
    "        \n",
    "        return cohen_kappa_score(y1_clean, y2_clean, weights='linear')\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "for factor, columns in factor_columns.items():\n",
    "    if len(columns) == 3 and all(col in df.columns for col in columns):\n",
    "        # name columns for easier reference\n",
    "        col_gpt = columns[0]\n",
    "        col_gem15 = columns[1]\n",
    "        col_gem25 = columns[2]\n",
    "        \n",
    "        # get valid data for each pair\n",
    "        valid_gpt_gem15 = df[[col_gpt, col_gem15]].dropna()\n",
    "        valid_gpt_gem25 = df[[col_gpt, col_gem25]].dropna()\n",
    "        valid_gem15_gem25 = df[[col_gem15, col_gem25]].dropna()\n",
    "        \n",
    "        if len(valid_gpt_gem15) == 0 or len(valid_gpt_gem25) == 0 or len(valid_gem15_gem25) == 0:\n",
    "            print(f\"insufficient data for {factor}\")\n",
    "            continue\n",
    "        \n",
    "        # calculate kendall's tau (for ordinal data)\n",
    "        tau_gpt_gem15, tau_p_gpt_gem15 = stats.kendalltau(valid_gpt_gem15[col_gpt], valid_gpt_gem15[col_gem15])\n",
    "        tau_gpt_gem25, tau_p_gpt_gem25 = stats.kendalltau(valid_gpt_gem25[col_gpt], valid_gpt_gem25[col_gem25])\n",
    "        tau_gem15_gem25, tau_p_gem15_gem25 = stats.kendalltau(valid_gem15_gem25[col_gem15], valid_gem15_gem25[col_gem25])\n",
    "        \n",
    "        # calculate spearman's rho (for ordinal data)\n",
    "        rho_gpt_gem15, rho_p_gpt_gem15 = stats.spearmanr(valid_gpt_gem15[col_gpt], valid_gpt_gem15[col_gem15])\n",
    "        rho_gpt_gem25, rho_p_gpt_gem25 = stats.spearmanr(valid_gpt_gem25[col_gpt], valid_gpt_gem25[col_gem25])\n",
    "        rho_gem15_gem25, rho_p_gem15_gem25 = stats.spearmanr(valid_gem15_gem25[col_gem15], valid_gem15_gem25[col_gem25])\n",
    "        \n",
    "        # calculate pearson's r (for comparison)\n",
    "        pearson_gpt_gem15, pearson_p_gpt_gem15 = stats.pearsonr(valid_gpt_gem15[col_gpt], valid_gpt_gem15[col_gem15])\n",
    "        pearson_gpt_gem25, pearson_p_gpt_gem25 = stats.pearsonr(valid_gpt_gem25[col_gpt], valid_gpt_gem25[col_gem25])\n",
    "        pearson_gem15_gem25, pearson_p_gem15_gem25 = stats.pearsonr(valid_gem15_gem25[col_gem15], valid_gem15_gem25[col_gem25])\n",
    "        \n",
    "        # calculate cohen's kappa (both linear and quadratic weights)\n",
    "        kappa_linear_gpt_gem15 = linear_kappa_ordinal(valid_gpt_gem15[col_gpt], valid_gpt_gem15[col_gem15])\n",
    "        kappa_linear_gpt_gem25 = linear_kappa_ordinal(valid_gpt_gem25[col_gpt], valid_gpt_gem25[col_gem25])\n",
    "        kappa_linear_gem15_gem25 = linear_kappa_ordinal(valid_gem15_gem25[col_gem15], valid_gem15_gem25[col_gem25])\n",
    "        \n",
    "        kappa_quad_gpt_gem15 = weighted_kappa_ordinal(valid_gpt_gem15[col_gpt], valid_gpt_gem15[col_gem15])\n",
    "        kappa_quad_gpt_gem25 = weighted_kappa_ordinal(valid_gpt_gem25[col_gpt], valid_gpt_gem25[col_gem25])\n",
    "        kappa_quad_gem15_gem25 = weighted_kappa_ordinal(valid_gem15_gem25[col_gem15], valid_gem15_gem25[col_gem25])\n",
    "        \n",
    "        # calculate agreement percentages\n",
    "        exact_gpt_gem15 = (valid_gpt_gem15[col_gpt] == valid_gpt_gem15[col_gem15]).mean() * 100\n",
    "        exact_gpt_gem25 = (valid_gpt_gem25[col_gpt] == valid_gpt_gem25[col_gem25]).mean() * 100\n",
    "        exact_gem15_gem25 = (valid_gem15_gem25[col_gem15] == valid_gem15_gem25[col_gem25]).mean() * 100\n",
    "        \n",
    "        within1_gpt_gem15 = (abs(valid_gpt_gem15[col_gpt] - valid_gpt_gem15[col_gem15]) <= 1).mean() * 100\n",
    "        within1_gpt_gem25 = (abs(valid_gpt_gem25[col_gpt] - valid_gpt_gem25[col_gem25]) <= 1).mean() * 100\n",
    "        within1_gem15_gem25 = (abs(valid_gem15_gem25[col_gem15] - valid_gem15_gem25[col_gem25]) <= 1).mean() * 100\n",
    "        \n",
    "        # store correlation stats\n",
    "        correlations = [\n",
    "            (f\"{model_pairs[0][0]} vs {model_pairs[0][1]}\", tau_gpt_gem15, rho_gpt_gem15, pearson_gpt_gem15),\n",
    "            (f\"{model_pairs[1][0]} vs {model_pairs[1][1]}\", tau_gpt_gem25, rho_gpt_gem25, pearson_gpt_gem25),\n",
    "            (f\"{model_pairs[2][0]} vs {model_pairs[2][1]}\", tau_gem15_gem25, rho_gem15_gem25, pearson_gem15_gem25)\n",
    "        ]\n",
    "        \n",
    "        for pair_str, tau, rho, pearson in correlations:\n",
    "            correlation_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model Pair': pair_str,\n",
    "                'Kendall Tau': tau,\n",
    "                'Spearman Rho': rho,\n",
    "                'Pearson r': pearson\n",
    "            })\n",
    "        \n",
    "        # store agreement stats\n",
    "        agreements = [\n",
    "            (f\"{model_pairs[0][0]} vs {model_pairs[0][1]}\", exact_gpt_gem15, within1_gpt_gem15),\n",
    "            (f\"{model_pairs[1][0]} vs {model_pairs[1][1]}\", exact_gpt_gem25, within1_gpt_gem25),\n",
    "            (f\"{model_pairs[2][0]} vs {model_pairs[2][1]}\", exact_gem15_gem25, within1_gem15_gem25)\n",
    "        ]\n",
    "        \n",
    "        for pair_str, exact, within1 in agreements:\n",
    "            agreement_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model Pair': pair_str,\n",
    "                'Exact Match %': exact,\n",
    "                'Within 1 Grade %': within1\n",
    "            })\n",
    "        \n",
    "        # store kappa stats\n",
    "        kappas = [\n",
    "            (f\"{model_pairs[0][0]} vs {model_pairs[0][1]}\", kappa_linear_gpt_gem15, kappa_quad_gpt_gem15),\n",
    "            (f\"{model_pairs[1][0]} vs {model_pairs[1][1]}\", kappa_linear_gpt_gem25, kappa_quad_gpt_gem25),\n",
    "            (f\"{model_pairs[2][0]} vs {model_pairs[2][1]}\", kappa_linear_gem15_gem25, kappa_quad_gem15_gem25)\n",
    "        ]\n",
    "        \n",
    "        for pair_str, linear_kappa, quad_kappa in kappas:\n",
    "            kappa_stats.append({\n",
    "                'Factor': factor,\n",
    "                'Model Pair': pair_str,\n",
    "                'Linear Weighted Kappa': linear_kappa,\n",
    "                'Quadratic Weighted Kappa': quad_kappa\n",
    "            })\n",
    "\n",
    "# convert to dataframes\n",
    "correlation_df = pd.DataFrame(correlation_stats)\n",
    "agreement_df = pd.DataFrame(agreement_stats)\n",
    "kappa_df = pd.DataFrame(kappa_stats)\n",
    "\n",
    "print(f\"calculated correlation metrics for {len(correlation_df)} factor-model combinations\")\n",
    "\n",
    "# display results\n",
    "print(\"\\nordinal correlation measures:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor in factor_columns.keys():\n",
    "    factor_data = correlation_df[correlation_df['Factor'] == factor]\n",
    "    if not factor_data.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        for _, row in factor_data.iterrows():\n",
    "            print(f\"   {row['Model Pair']:30}: tau={row['Kendall Tau']:6.3f}, rho={row['Spearman Rho']:6.3f}, r={row['Pearson r']:6.3f}\")\n",
    "\n",
    "print(\"\\ncohen's kappa (ordinal agreement):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor in factor_columns.keys():\n",
    "    factor_data = kappa_df[kappa_df['Factor'] == factor]\n",
    "    if not factor_data.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        for _, row in factor_data.iterrows():\n",
    "            print(f\"   {row['Model Pair']:30}: linear κ={row['Linear Weighted Kappa']:6.3f}, quad κ={row['Quadratic Weighted Kappa']:6.3f}\")\n",
    "\n",
    "print(\"\\nagreement percentages:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for factor in factor_columns.keys():\n",
    "    factor_data = agreement_df[agreement_df['Factor'] == factor]\n",
    "    if not factor_data.empty:\n",
    "        print(f\"\\n{factor}:\")\n",
    "        for _, row in factor_data.iterrows():\n",
    "            print(f\"   {row['Model Pair']:30}: exact={row['Exact Match %']:5.1f}%, within1={row['Within 1 Grade %']:5.1f}%\")\n",
    "\n",
    "# create visualizations\n",
    "print(f\"\\ncreating enhanced correlation visualizations...\")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# comprehensive correlation heatmaps (3 measures)\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 16))\n",
    "\n",
    "# kendall's tau\n",
    "kendall_pivot = pd.pivot_table(correlation_df, index='Factor', columns='Model Pair', values='Kendall Tau')\n",
    "sns.heatmap(kendall_pivot, annot=True, cmap='YlGnBu', fmt='.3f', vmin=0, vmax=1, \n",
    "            ax=axes[0], cbar_kws={'label': \"Kendall's τ\"})\n",
    "axes[0].set_title(\"Kendall's Tau (Ordinal Correlation)\\nPreferred for Ordinal Data\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# spearman's rho\n",
    "spearman_pivot = pd.pivot_table(correlation_df, index='Factor', columns='Model Pair', values='Spearman Rho')\n",
    "sns.heatmap(spearman_pivot, annot=True, cmap='YlGnBu', fmt='.3f', vmin=0, vmax=1, \n",
    "            ax=axes[1], cbar_kws={'label': \"Spearman's ρ\"})\n",
    "axes[1].set_title(\"Spearman's Rho (Rank Correlation)\\nRobust to Outliers\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# pearson's r\n",
    "pearson_pivot = pd.pivot_table(correlation_df, index='Factor', columns='Model Pair', values='Pearson r')\n",
    "sns.heatmap(pearson_pivot, annot=True, cmap='YlGnBu', fmt='.3f', vmin=0, vmax=1, \n",
    "            ax=axes[2], cbar_kws={'label': \"Pearson's r\"})\n",
    "axes[2].set_title(\"Pearson's r (Linear Correlation)\\nFor Comparison\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Model Pair', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('AI Factor', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}enhanced_correlation_heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# cohen's kappa heatmaps\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# linear weighted kappa\n",
    "linear_kappa_pivot = pd.pivot_table(kappa_df, index='Factor', columns='Model Pair', values='Linear Weighted Kappa')\n",
    "sns.heatmap(linear_kappa_pivot, annot=True, cmap='RdYlGn', fmt='.3f', vmin=0, vmax=1, \n",
    "            ax=axes[0], cbar_kws={'label': 'Linear Weighted κ'})\n",
    "axes[0].set_title(\"Cohen's Kappa - Linear Weights\\nOrdinal Agreement Measure\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# quadratic weighted kappa\n",
    "quad_kappa_pivot = pd.pivot_table(kappa_df, index='Factor', columns='Model Pair', values='Quadratic Weighted Kappa')\n",
    "sns.heatmap(quad_kappa_pivot, annot=True, cmap='RdYlGn', fmt='.3f', vmin=0, vmax=1, \n",
    "            ax=axes[1], cbar_kws={'label': 'Quadratic Weighted κ'})\n",
    "axes[1].set_title(\"Cohen's Kappa - Quadratic Weights\\nPenalizes Larger Disagreements More\", fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Model Pair', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('AI Factor', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}cohens_kappa_heatmaps.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(f\"enhanced correlation visualizations created:\")\n",
    "print(f\"   enhanced_correlation_heatmaps.png\")\n",
    "print(f\"   cohens_kappa_heatmaps.png\")\n",
    "\n",
    "print(f\"\\nenhanced correlation analysis complete!\")\n",
    "print(f\"all files saved to: {output_dir}\")\n",
    "\n",
    "if not correlation_df.empty:\n",
    "    print(f\"\\nkey findings:\")\n",
    "    print(f\"   average kendall's τ: {correlation_df['Kendall Tau'].mean():.3f} (preferred for ordinal)\")\n",
    "    print(f\"   average spearman's ρ: {correlation_df['Spearman Rho'].mean():.3f}\")\n",
    "    print(f\"   average pearson's r: {correlation_df['Pearson r'].mean():.3f}\")\n",
    "    print(f\"   average linear κ: {kappa_df['Linear Weighted Kappa'].mean():.3f}\")\n",
    "    print(f\"   average quadratic κ: {kappa_df['Quadratic Weighted Kappa'].mean():.3f}\")\n",
    "    print(f\"   average within 1 grade: {agreement_df['Within 1 Grade %'].mean():.1f}%\")\n",
    "    \n",
    "    # identify best and worst performing factors\n",
    "    factor_performance = correlation_df.groupby('Factor')['Kendall Tau'].mean().sort_values(ascending=False)\n",
    "    best_factor = factor_performance.index[0]\n",
    "    worst_factor = factor_performance.index[-1]\n",
    "    \n",
    "    print(f\"\\nfactor with highest agreement: {best_factor} (τ={factor_performance.iloc[0]:.3f})\")\n",
    "    print(f\"factor with lowest agreement: {worst_factor} (τ={factor_performance.iloc[-1]:.3f})\")\n",
    "    \n",
    "    # model pair performance\n",
    "    pair_performance = correlation_df.groupby('Model Pair')['Kendall Tau'].mean().sort_values(ascending=False)\n",
    "    print(f\"\\nmodel pair rankings (by kendall's τ):\")\n",
    "    for i, (pair, score) in enumerate(pair_performance.items(), 1):\n",
    "        print(f\"   {i}. {pair}: {score:.3f}\")\n",
    "\n",
    "print(f\"\\nfiles created:\")\n",
    "print(f\"   visualizations:\")\n",
    "print(f\"      • enhanced_correlation_heatmaps.png - kendall, spearman, pearson\")\n",
    "print(f\"      • cohens_kappa_heatmaps.png - linear and quadratic weighted kappa\")\n",
    "\n",
    "print(f\"\\nresearch implications:\")\n",
    "print(f\"   demonstrates robust measurement across different llm architectures\")\n",
    "print(f\"   provides multiple validation metrics appropriate for ordinal data\")\n",
    "print(f\"   cohen's kappa confirms inter-rater reliability for thesis methodology\")\n",
    "print(f\"   high within-1-grade agreement shows practical robustness\")\n",
    "print(f\"   perfect for thesis robustness and methodology validation sections!\")\n",
    "\n",
    "# quick reference - agreement interpretation\n",
    "print(f\"\\nquick reference - agreement interpretation:\")\n",
    "print(f\"   cohen's kappa:\")\n",
    "print(f\"      >0.80: excellent agreement\")\n",
    "print(f\"      0.60-0.80: good agreement\") \n",
    "print(f\"      0.40-0.60: moderate agreement\")\n",
    "print(f\"      <0.40: poor agreement\")\n",
    "print(f\"   within 1 grade agreement:\")\n",
    "print(f\"      >90%: excellent robustness\")\n",
    "print(f\"      >80%: good robustness\")\n",
    "print(f\"      >70%: acceptable robustness\")\n",
    "print(f\"   kendall's tau (ordinal correlation):\")\n",
    "print(f\"      >0.70: strong relationship\")\n",
    "print(f\"      >0.50: moderate relationship\")\n",
    "print(f\"      >0.30: weak relationship\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84ddbd-54ea-4fc7-b57f-83a49bca9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# robust momentum returns calculator - cumulative approach\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class RobustMomentumCalculator:\n",
    "    \"\"\"calculate momentum returns using cumulative daily returns approach\"\"\"\n",
    "    \n",
    "    def __init__(self, daily_prices_path, final_dataset_path):\n",
    "        self.daily_prices_path = daily_prices_path\n",
    "        self.final_dataset_path = final_dataset_path\n",
    "        \n",
    "        print(\"robust momentum calculator initialized\")\n",
    "        print(f\"   daily prices: {daily_prices_path}\")\n",
    "        print(f\"   final dataset: {final_dataset_path}\")\n",
    "        print(\"   uses cumulative daily returns to avoid price discontinuities\")\n",
    "    \n",
    "    def load_and_examine_data(self):\n",
    "        \"\"\"load and examine data with focus on quality\"\"\"\n",
    "        print(\"\\nloading and examining data\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        # load daily prices\n",
    "        print(\"loading daily prices...\")\n",
    "        daily_cols_needed = ['gvkey', 'datadate', 'prccd', 'ajexdi', 'cshoc']\n",
    "        daily_sample = pd.read_csv(self.daily_prices_path, nrows=5)\n",
    "        available_cols = [col for col in daily_cols_needed if col in daily_sample.columns]\n",
    "        print(f\"available columns: {available_cols}\")\n",
    "        \n",
    "        self.daily_prices = pd.read_csv(self.daily_prices_path, usecols=available_cols, dtype={'gvkey': str})\n",
    "        \n",
    "        # standardize gvkey\n",
    "        self.daily_prices['gvkey'] = self.daily_prices['gvkey'].str.strip().str.zfill(6)\n",
    "        self.daily_prices['datadate'] = pd.to_datetime(self.daily_prices['datadate'])\n",
    "        \n",
    "        # use adjusted prices if available, otherwise raw prices\n",
    "        if 'ajexdi' in self.daily_prices.columns:\n",
    "            self.daily_prices['adj_price'] = self.daily_prices['prccd'] / self.daily_prices['ajexdi']\n",
    "            print(\"   using split/dividend adjusted prices\")\n",
    "        else:\n",
    "            self.daily_prices['adj_price'] = self.daily_prices['prccd']\n",
    "            print(\"   no adjustment factors - using raw prices\")\n",
    "        \n",
    "        # clean data\n",
    "        original_count = len(self.daily_prices)\n",
    "        self.daily_prices = self.daily_prices[\n",
    "            (self.daily_prices['adj_price'].notna()) & \n",
    "            (self.daily_prices['adj_price'] > 0)\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"   cleaned: {original_count:,} -> {len(self.daily_prices):,} ({len(self.daily_prices)/original_count:.1%})\")\n",
    "        \n",
    "        self.daily_prices = self.daily_prices.sort_values(['gvkey', 'datadate']).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"daily prices: {self.daily_prices.shape}\")\n",
    "        print(f\"   date range: {self.daily_prices['datadate'].min()} to {self.daily_prices['datadate'].max()}\")\n",
    "        print(f\"   unique gvkeys: {self.daily_prices['gvkey'].nunique()}\")\n",
    "        \n",
    "        # load final dataset\n",
    "        print(\"\\nloading final dataset...\")\n",
    "        self.final_dataset = pd.read_csv(self.final_dataset_path, dtype={'gvkey': str})\n",
    "        self.final_dataset['gvkey'] = self.final_dataset['gvkey'].str.strip().str.zfill(6)\n",
    "        self.final_dataset['filingDate'] = pd.to_datetime(self.final_dataset['filingDate'])\n",
    "        \n",
    "        print(f\"final dataset: {self.final_dataset.shape}\")\n",
    "        print(f\"   unique gvkeys: {self.final_dataset['gvkey'].nunique()}\")\n",
    "        \n",
    "        # check overlap\n",
    "        daily_gvkeys = set(self.daily_prices['gvkey'].unique())\n",
    "        final_gvkeys = set(self.final_dataset['gvkey'].unique())\n",
    "        overlap = daily_gvkeys.intersection(final_gvkeys)\n",
    "        \n",
    "        print(f\"\\ngvkey overlap: {len(overlap)}/{len(final_gvkeys)} ({len(overlap)/len(final_gvkeys):.1%})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def calculate_clean_daily_returns(self):\n",
    "        \"\"\"calculate clean daily returns for all firms\"\"\"\n",
    "        print(\"\\ncalculating clean daily returns\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        # calculate daily returns with robust cleaning\n",
    "        self.daily_prices['price_lag'] = self.daily_prices.groupby('gvkey')['adj_price'].shift(1)\n",
    "        self.daily_prices['daily_return'] = (self.daily_prices['adj_price'] / self.daily_prices['price_lag']) - 1\n",
    "        \n",
    "        # remove extreme daily returns and missing values  \n",
    "        original_count = len(self.daily_prices)\n",
    "        self.daily_prices = self.daily_prices[\n",
    "            (self.daily_prices['daily_return'].between(-0.50, 0.50)) &  # ±50% max daily\n",
    "            (self.daily_prices['daily_return'].notna())\n",
    "        ].copy()\n",
    "        \n",
    "        print(f\"   after return filtering: {original_count:,} -> {len(self.daily_prices):,}\")\n",
    "        print(f\"   daily return stats:\")\n",
    "        returns = self.daily_prices['daily_return']\n",
    "        print(f\"      mean: {returns.mean():.6f}\")\n",
    "        print(f\"      std:  {returns.std():.6f}\")\n",
    "        print(f\"      min:  {returns.min():.6f}\")\n",
    "        print(f\"      max:  {returns.max():.6f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def calculate_momentum_via_cumulative_returns(self, months_back=[1, 2, 3]):\n",
    "        \"\"\"calculate momentum using cumulative daily returns approach\"\"\"\n",
    "        print(f\"\\ncalculating momentum via cumulative returns\")\n",
    "        print(\"=\" * 55)\n",
    "        print(f\"   months back: {months_back}\")\n",
    "        print(f\"   method: cumulative daily returns over ~21 trading days with winsorization\")\n",
    "        \n",
    "        momentum_results = []\n",
    "        \n",
    "        # get overlapping firms\n",
    "        daily_gvkeys = set(self.daily_prices['gvkey'].unique())\n",
    "        final_gvkeys = set(self.final_dataset['gvkey'].unique())\n",
    "        processable_gvkeys = daily_gvkeys.intersection(final_gvkeys)\n",
    "        \n",
    "        print(f\"   processing {len(processable_gvkeys)} firms\")\n",
    "        \n",
    "        # statistics tracking\n",
    "        stats = {month: {'attempts': 0, 'successful': 0, 'avg_days': 0} for month in months_back}\n",
    "        \n",
    "        for gvkey in tqdm(processable_gvkeys, desc=\"calculating momentum\"):\n",
    "            # get firm data\n",
    "            firm_data = self.daily_prices[self.daily_prices['gvkey'] == gvkey].copy()\n",
    "            firm_filings = self.final_dataset[self.final_dataset['gvkey'] == gvkey].copy()\n",
    "            \n",
    "            if len(firm_data) < 100:  # need sufficient history\n",
    "                continue\n",
    "            \n",
    "            # calculate log returns for better aggregation properties\n",
    "            firm_data['log_return'] = np.log(1 + firm_data['daily_return'])\n",
    "            firm_data = firm_data.sort_values('datadate')\n",
    "            \n",
    "            # process each filing\n",
    "            for _, filing_row in firm_filings.iterrows():\n",
    "                filing_date = filing_row['filingDate']\n",
    "                year = filing_row.get('Year', filing_date.year)\n",
    "                \n",
    "                result = {\n",
    "                    'gvkey': gvkey,\n",
    "                    'Year': year,\n",
    "                    'filing_date': filing_date\n",
    "                }\n",
    "                \n",
    "                # calculate returns for each lookback period\n",
    "                for months in months_back:\n",
    "                    stats[months]['attempts'] += 1\n",
    "                    \n",
    "                    # define lookback period (approximately months * 21 trading days)\n",
    "                    target_days = months * 21\n",
    "                    lookback_start = filing_date - pd.DateOffset(days=int(months * 35))  # buffer for weekends\n",
    "                    lookback_end = filing_date - pd.DateOffset(days=5)  # small buffer before filing\n",
    "                    \n",
    "                    # get data in lookback window\n",
    "                    window_data = firm_data[\n",
    "                        (firm_data['datadate'] >= lookback_start) &\n",
    "                        (firm_data['datadate'] <= lookback_end)\n",
    "                    ].copy()\n",
    "                    \n",
    "                    if len(window_data) < 10:  # need minimum observations\n",
    "                        result[f'return_t_minus_{months}m'] = np.nan\n",
    "                        result[f'n_days_t_minus_{months}m'] = 0\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        # take the most recent 'target_days' observations\n",
    "                        recent_data = window_data.tail(min(target_days, len(window_data)))\n",
    "                        \n",
    "                        # calculate cumulative return using simple compounding\n",
    "                        daily_returns = recent_data['daily_return'].values\n",
    "                        cumulative_return = np.prod(1 + daily_returns) - 1\n",
    "                        \n",
    "                        # store results (no hard caps - will winsorize later)\n",
    "                        result[f'return_t_minus_{months}m'] = cumulative_return\n",
    "                        result[f'n_days_t_minus_{months}m'] = len(recent_data)\n",
    "                        result[f'start_date_t_minus_{months}m'] = recent_data['datadate'].iloc[0]\n",
    "                        result[f'end_date_t_minus_{months}m'] = recent_data['datadate'].iloc[-1]\n",
    "                        \n",
    "                        # update statistics\n",
    "                        stats[months]['successful'] += 1\n",
    "                        stats[months]['avg_days'] += len(recent_data)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        result[f'return_t_minus_{months}m'] = np.nan\n",
    "                        result[f'n_days_t_minus_{months}m'] = 0\n",
    "                        continue\n",
    "                \n",
    "                momentum_results.append(result)\n",
    "        \n",
    "        # calculate final statistics\n",
    "        for month in stats:\n",
    "            if stats[month]['successful'] > 0:\n",
    "                stats[month]['avg_days'] /= stats[month]['successful']\n",
    "        \n",
    "        if momentum_results:\n",
    "            self.momentum_data = pd.DataFrame(momentum_results)\n",
    "            \n",
    "            # apply winsorization to handle remaining extreme values\n",
    "            print(f\"\\napplying winsorization to momentum returns:\")\n",
    "            for month in months_back:\n",
    "                return_col = f'return_t_minus_{month}m'\n",
    "                if return_col in self.momentum_data.columns:\n",
    "                    original_returns = self.momentum_data[return_col].dropna()\n",
    "                    if len(original_returns) > 0:\n",
    "                        # winsorize at 1st and 99th percentiles\n",
    "                        p01 = original_returns.quantile(0.01)\n",
    "                        p99 = original_returns.quantile(0.99)\n",
    "                        \n",
    "                        winsorized_count = ((original_returns < p01) | (original_returns > p99)).sum()\n",
    "                        \n",
    "                        # apply winsorization\n",
    "                        self.momentum_data[return_col] = self.momentum_data[return_col].clip(lower=p01, upper=p99)\n",
    "                        \n",
    "                        print(f\"   t-{month}m: winsorized {winsorized_count} values at [{p01:.3f}, {p99:.3f}]\")\n",
    "            \n",
    "            print(f\"\\nmomentum calculations completed:\")\n",
    "            print(f\"   total observations: {len(self.momentum_data)}\")\n",
    "            \n",
    "            # success rates\n",
    "            print(f\"\\nsuccess rate by lookback period:\")\n",
    "            for month in months_back:\n",
    "                total = stats[month]['attempts']\n",
    "                success = stats[month]['successful']\n",
    "                avg_days = stats[month]['avg_days']\n",
    "                rate = success/total*100 if total > 0 else 0\n",
    "                print(f\"   t-{month}m: {success:4d}/{total:4d} ({rate:5.1f}%) | avg days: {avg_days:5.1f}\")\n",
    "            \n",
    "            # return statistics after winsorization\n",
    "            print(f\"\\nmomentum return statistics (after winsorization):\")\n",
    "            for month in months_back:\n",
    "                return_col = f'return_t_minus_{month}m'\n",
    "                if return_col in self.momentum_data.columns:\n",
    "                    returns = self.momentum_data[return_col].dropna()\n",
    "                    if len(returns) > 0:\n",
    "                        print(f\"   t-{month}m: mean={returns.mean():7.4f}, std={returns.std():6.4f}, \"\n",
    "                              f\"min={returns.min():7.4f}, max={returns.max():7.4f}\")\n",
    "                        \n",
    "                        # check for remaining extremes\n",
    "                        extreme_count = ((returns < -0.5) | (returns > 0.5)).sum()\n",
    "                        if extreme_count > 0:\n",
    "                            print(f\"           {extreme_count} returns still >50% (after winsorization)\")\n",
    "                        else:\n",
    "                            print(f\"           all returns within reasonable bounds\")\n",
    "        else:\n",
    "            raise ValueError(\"no momentum returns calculated!\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def merge_with_final_dataset(self):\n",
    "        \"\"\"merge momentum data with final dataset\"\"\"\n",
    "        print(\"\\nmerging with final dataset\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        # merge on gvkey and year\n",
    "        momentum_cols = [col for col in self.momentum_data.columns \n",
    "                        if col not in ['gvkey', 'Year', 'filing_date']]\n",
    "        merge_cols = ['gvkey', 'Year'] + momentum_cols\n",
    "        \n",
    "        self.final_dataset_with_momentum = pd.merge(\n",
    "            self.final_dataset,\n",
    "            self.momentum_data[merge_cols],\n",
    "            on=['gvkey', 'Year'],\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        total_obs = len(self.final_dataset)\n",
    "        \n",
    "        print(f\"merge completed:\")\n",
    "        print(f\"   total observations: {total_obs}\")\n",
    "        print(f\"   new momentum columns: {len(momentum_cols)}\")\n",
    "        \n",
    "        # availability check\n",
    "        print(f\"\\nfinal momentum availability:\")\n",
    "        for month in [1, 2, 3]:\n",
    "            return_col = f'return_t_minus_{month}m'\n",
    "            if return_col in self.final_dataset_with_momentum.columns:\n",
    "                available = self.final_dataset_with_momentum[return_col].notna().sum()\n",
    "                print(f\"   t-{month}m: {available:4d}/{total_obs:4d} ({available/total_obs:.1%})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def validate_momentum_quality(self):\n",
    "        \"\"\"perform quality checks on momentum returns\"\"\"\n",
    "        print(f\"\\nmomentum quality validation\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        for month in [1, 2, 3]:\n",
    "            return_col = f'return_t_minus_{month}m'\n",
    "            if return_col in self.final_dataset_with_momentum.columns:\n",
    "                returns = self.final_dataset_with_momentum[return_col].dropna()\n",
    "                \n",
    "                if len(returns) > 0:\n",
    "                    print(f\"\\nt-{month}m quality check:\")\n",
    "                    print(f\"   valid observations: {len(returns)}\")\n",
    "                    print(f\"   mean: {returns.mean():8.4f}\")\n",
    "                    print(f\"   std:  {returns.std():8.4f}\")\n",
    "                    print(f\"   skew: {returns.skew():8.4f}\")\n",
    "                    print(f\"   kurt: {returns.kurtosis():8.4f}\")\n",
    "                    \n",
    "                    # percentile analysis\n",
    "                    percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "                    pct_values = returns.quantile([p/100 for p in percentiles])\n",
    "                    print(f\"   percentiles: \" + \" | \".join([f\"p{p}={pct_values[p/100]:.3f}\" for p in [1, 5, 95, 99]]))\n",
    "                    \n",
    "                    # flag suspicious patterns\n",
    "                    if abs(returns.mean()) > 0.05:\n",
    "                        print(f\"   high average return ({returns.mean():.3f}) - check for data issues\")\n",
    "                    if returns.std() > 0.3:\n",
    "                        print(f\"   high volatility ({returns.std():.3f}) - possible remaining outliers\")\n",
    "                    if abs(returns.skew()) > 3:\n",
    "                        print(f\"   high skewness ({returns.skew():.2f}) - asymmetric distribution\")\n",
    "                    \n",
    "                    # check extreme values\n",
    "                    extreme_positive = (returns > 0.5).sum()\n",
    "                    extreme_negative = (returns < -0.5).sum()\n",
    "                    if extreme_positive + extreme_negative > 0:\n",
    "                        print(f\"   extreme values: {extreme_positive} >50%, {extreme_negative} <-50%\")\n",
    "                    else:\n",
    "                        print(f\"   no extreme values detected\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def save_enhanced_dataset(self, output_path=None):\n",
    "        \"\"\"save enhanced dataset\"\"\"\n",
    "        print(\"\\nsaving enhanced dataset\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        if output_path is None:\n",
    "            output_path = self.final_dataset_path.replace('.csv', '_with_robust_momentum.csv')\n",
    "        \n",
    "        self.final_dataset_with_momentum.to_csv(output_path, index=False)\n",
    "        \n",
    "        print(f\"dataset saved: {output_path}\")\n",
    "        print(f\"   shape: {self.final_dataset_with_momentum.shape}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        \"\"\"run complete robust momentum analysis\"\"\"\n",
    "        print(\"running robust momentum analysis\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        try:\n",
    "            self.load_and_examine_data()\n",
    "            self.calculate_clean_daily_returns()\n",
    "            self.calculate_momentum_via_cumulative_returns()\n",
    "            self.merge_with_final_dataset()\n",
    "            self.validate_momentum_quality()\n",
    "            output_path = self.save_enhanced_dataset()\n",
    "            \n",
    "            print(f\"\\nrobust momentum analysis complete!\")\n",
    "            print(f\"   used cumulative daily returns approach\")\n",
    "            print(f\"   applied strict outlier filtering\")\n",
    "            print(f\"   quality validated\")\n",
    "            print(f\"   ready for regression analysis!\")\n",
    "            \n",
    "            return self.final_dataset_with_momentum, output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nerror: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None, None\n",
    "\n",
    "# main execution\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"robust momentum calculator\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    calculator = RobustMomentumCalculator(\n",
    "        daily_prices_path=\"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Controls/daily.csv\",\n",
    "        final_dataset_path=\"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered_with_corrected_factor_loadings.csv\"\n",
    "    )\n",
    "    \n",
    "    enhanced_dataset, output_path = calculator.run_complete_analysis()\n",
    "    \n",
    "    if enhanced_dataset is not None:\n",
    "        print(f\"\\nsuccess! robust momentum returns calculated!\")\n",
    "        print(f\"output: {output_path}\")\n",
    "    else:\n",
    "        print(f\"\\nanalysis failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9811da59-0e39-441d-b419-9ca69c4d304f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIK', 'Company Name', 'Sector', 'Ticker', 'Year', 'filingDate', 'form', 'gvkey', 'AI Washing Index_flash1_5', 'AI Washing Index_flash2_5', 'AI Washing Index_gpt4o', 'Disclosure Sentiment_flash1_5', 'Disclosure Sentiment_flash2_5', 'Disclosure Sentiment_gpt4o', 'Forward-Looking_flash1_5', 'Forward-Looking_flash2_5', 'Forward-Looking_gpt4o', 'Key AI Terms_flash1_5', 'Key AI Terms_flash2_5', 'Key AI Terms_gpt4o', 'Overall Summary_flash1_5', 'Overall Summary_flash2_5', 'Overall Summary_gpt4o', 'Risk - External Threats_flash1_5', 'Risk - External Threats_flash2_5', 'Risk - External Threats_gpt4o', 'Risk - Non-Adoption_flash1_5', 'Risk - Non-Adoption_flash2_5', 'Risk - Non-Adoption_gpt4o', 'Risk - Own Adoption_flash1_5', 'Risk - Own Adoption_flash2_5', 'Risk - Own Adoption_gpt4o', 'Strategic Depth_flash1_5', 'Strategic Depth_flash2_5', 'Strategic Depth_gpt4o', 'Talent & Investment_flash1_5', 'Talent & Investment_flash2_5', 'Talent & Investment_gpt4o', 'AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric', 'AI Washing Index_gpt4o_Numeric', 'Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric', 'Disclosure Sentiment_gpt4o_Numeric', 'Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric', 'Forward-Looking_gpt4o_Numeric', 'Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric', 'Risk - External Threats_gpt4o_Numeric', 'Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric', 'Risk - Non-Adoption_gpt4o_Numeric', 'Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric', 'Risk - Own Adoption_gpt4o_Numeric', 'Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric', 'Strategic Depth_gpt4o_Numeric', 'Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric', 'Talent & Investment_gpt4o_Numeric', 'Cum_Score_flash1_5', 'Cum_Score_flash2_5', 'Cum_Score_gpt4o', 'price_t0', 'price_t12', 'price_t3', 'price_t6', 'price_t9', 'return_12mo', 'return_12mo_annualized', 'return_3mo', 'return_3mo_annualized', 'return_6mo', 'return_6mo_annualized', 'return_9mo', 'return_9mo_annualized', 'excess_return_12mo', 'excess_return_12mo_annualized', 'excess_return_3mo', 'excess_return_3mo_annualized', 'excess_return_6mo', 'excess_return_6mo_annualized', 'excess_return_9mo', 'excess_return_9mo_annualized', 'ff_cma', 'ff_hml', 'ff_mktrf', 'ff_rf', 'ff_rmw', 'ff_smb', 'ff_umd', 'rf_12m_cumulative', 'rf_3m_cumulative', 'rf_6m_cumulative', 'rf_9m_cumulative', 'sector_ggroup', 'sector_gind', 'sector_gsector', 'sector_gsubind', 'fund_atq', 'fund_cheq', 'fund_cshoq', 'fund_dlttq', 'fund_epsfxq', 'fund_niq', 'fund_oiadpq', 'fund_revty', 'fund_teqq', 'calc_asset_turnover', 'calc_debt_to_assets', 'calc_debt_to_equity', 'calc_enterprise_value', 'calc_log_market_cap', 'calc_log_total_assets', 'calc_market_to_book', 'calc_operating_margin', 'calc_price_to_book', 'calc_price_to_earnings', 'calc_profit_margin', 'calc_roa', 'calc_roe', 'alpha_t3', 'alpha_t3_tstat', 'r_squared_t3', 'n_obs_t3', 'beta_mktrf_t3', 'beta_mktrf_t3_tstat', 'beta_mktrf_t3_pvalue', 'beta_smb_t3', 'beta_smb_t3_tstat', 'beta_smb_t3_pvalue', 'beta_hml_t3', 'beta_hml_t3_tstat', 'beta_hml_t3_pvalue', 'beta_rmw_t3', 'beta_rmw_t3_tstat', 'beta_rmw_t3_pvalue', 'beta_cma_t3', 'beta_cma_t3_tstat', 'beta_cma_t3_pvalue', 'beta_umd_t3', 'beta_umd_t3_tstat', 'beta_umd_t3_pvalue', 'alpha_t6', 'alpha_t6_tstat', 'r_squared_t6', 'n_obs_t6', 'beta_mktrf_t6', 'beta_mktrf_t6_tstat', 'beta_mktrf_t6_pvalue', 'beta_smb_t6', 'beta_smb_t6_tstat', 'beta_smb_t6_pvalue', 'beta_hml_t6', 'beta_hml_t6_tstat', 'beta_hml_t6_pvalue', 'beta_rmw_t6', 'beta_rmw_t6_tstat', 'beta_rmw_t6_pvalue', 'beta_cma_t6', 'beta_cma_t6_tstat', 'beta_cma_t6_pvalue', 'beta_umd_t6', 'beta_umd_t6_tstat', 'beta_umd_t6_pvalue', 'alpha_t9', 'alpha_t9_tstat', 'r_squared_t9', 'n_obs_t9', 'beta_mktrf_t9', 'beta_mktrf_t9_tstat', 'beta_mktrf_t9_pvalue', 'beta_smb_t9', 'beta_smb_t9_tstat', 'beta_smb_t9_pvalue', 'beta_hml_t9', 'beta_hml_t9_tstat', 'beta_hml_t9_pvalue', 'beta_rmw_t9', 'beta_rmw_t9_tstat', 'beta_rmw_t9_pvalue', 'beta_cma_t9', 'beta_cma_t9_tstat', 'beta_cma_t9_pvalue', 'beta_umd_t9', 'beta_umd_t9_tstat', 'beta_umd_t9_pvalue', 'alpha_t12', 'alpha_t12_tstat', 'r_squared_t12', 'n_obs_t12', 'beta_mktrf_t12', 'beta_mktrf_t12_tstat', 'beta_mktrf_t12_pvalue', 'beta_smb_t12', 'beta_smb_t12_tstat', 'beta_smb_t12_pvalue', 'beta_hml_t12', 'beta_hml_t12_tstat', 'beta_hml_t12_pvalue', 'beta_rmw_t12', 'beta_rmw_t12_tstat', 'beta_rmw_t12_pvalue', 'beta_cma_t12', 'beta_cma_t12_tstat', 'beta_cma_t12_pvalue', 'beta_umd_t12', 'beta_umd_t12_tstat', 'beta_umd_t12_pvalue', 'return_t_minus_1m', 'n_days_t_minus_1m', 'start_date_t_minus_1m', 'end_date_t_minus_1m', 'return_t_minus_2m', 'n_days_t_minus_2m', 'start_date_t_minus_2m', 'end_date_t_minus_2m', 'return_t_minus_3m', 'n_days_t_minus_3m', 'start_date_t_minus_3m', 'end_date_t_minus_3m']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path\n",
    "data_path = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered_with_corrected_factor_loadings_with_robust_momentum.csv\"\n",
    "\n",
    "# Load the DataFrame\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Print column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0e618f-ee65-4554-818a-1d82703a3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 RUNNING COMPREHENSIVE ENDOGENEITY TESTING\n",
      "📊 Loading data for endogeneity testing...\n",
      "✅ Created Strategic_Depth_Average: 3,995 obs\n",
      "✅ Created AI_Sentiment_Average: 3,995 obs\n",
      "✅ Created Risk_Own_Adoption_Average: 3,995 obs\n",
      "✅ Created Risk_External_Threats_Average: 3,995 obs\n",
      "✅ Created Risk_Non-Adoption_Average: 3,995 obs\n",
      "✅ Created Forward_Looking_Average: 3,995 obs\n",
      "✅ Created AI_Washing_Average: 3,995 obs\n",
      "✅ Created Talent_Investment_Average: 3,995 obs\n",
      "🔧 Creating management quality proxies...\n",
      "✅ Management quality proxies created\n",
      "🔧 Creating additional lagged variables...\n",
      "✅ Additional lagged variables created\n",
      "\n",
      "🚀 Running comprehensive endogeneity testing...\n",
      "\n",
      "🔬 Testing for Omitted Variable Bias...\n",
      "Available standard controls: 6\n",
      "Available management proxies: 9\n",
      "  Strategic Depth: -0.032 → -0.030 (+7.0%)\n",
      "  AI Sentiment: -0.036 → -0.036 (+1.1%)\n",
      "  Risk Own Adoption: -0.049 → -0.044 (+10.2%)\n",
      "  Risk External Threats: -0.012 → -0.012 (-1.4%)\n",
      "  Risk Non-Adoption: -0.051 → -0.067 (-31.8%)\n",
      "  Forward Looking: -0.057 → -0.049 (+13.1%)\n",
      "  AI Washing: -0.047 → -0.049 (-3.9%)\n",
      "  Talent Investment: -0.063 → -0.060 (+5.8%)\n",
      "✅ Omitted Variable Bias testing complete\n",
      "\n",
      "🔬 Testing for Reverse Causality...\n",
      "Available lagged performance vars: ['return_t_minus_1m', 'return_t_minus_2m', 'return_t_minus_3m', 'calc_roa_lag1', 'calc_log_market_cap_lag1']\n",
      "✅ Reverse Causality testing complete\n",
      "\n",
      "🔬 Testing Coefficient Stability...\n",
      "✅ Coefficient Stability testing complete\n",
      "✅ All endogeneity tests complete\n",
      "\n",
      "================================================================================\n",
      "📊 ENDOGENEITY TESTING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "1. OMITTED VARIABLE BIAS TEST:\n",
      "----------------------------------------\n",
      "Strategic Depth:\n",
      "  Baseline: -0.032***\n",
      "  With mgmt proxies: -0.030***\n",
      "  Change: +7.0%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "AI Sentiment:\n",
      "  Baseline: -0.036***\n",
      "  With mgmt proxies: -0.036***\n",
      "  Change: +1.1%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "Risk Own Adoption:\n",
      "  Baseline: -0.049**\n",
      "  With mgmt proxies: -0.044*\n",
      "  Change: +10.2%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "Risk External Threats:\n",
      "  Baseline: -0.012\n",
      "  With mgmt proxies: -0.012\n",
      "  Change: -1.4%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "Risk Non-Adoption:\n",
      "  Baseline: -0.051***\n",
      "  With mgmt proxies: -0.067***\n",
      "  Change: -31.8%\n",
      "  Assessment: ⚠️ POTENTIAL BIAS (large change)\n",
      "Forward Looking:\n",
      "  Baseline: -0.057***\n",
      "  With mgmt proxies: -0.049***\n",
      "  Change: +13.1%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "AI Washing:\n",
      "  Baseline: -0.047***\n",
      "  With mgmt proxies: -0.049***\n",
      "  Change: -3.9%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "Talent Investment:\n",
      "  Baseline: -0.063***\n",
      "  With mgmt proxies: -0.060***\n",
      "  Change: +5.8%\n",
      "  Assessment: ✅ ROBUST (small change)\n",
      "\n",
      "2. REVERSE CAUSALITY TEST:\n",
      "----------------------------------------\n",
      "Strategic Depth:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ✅ FORWARD PREDICTIVE POWER: -0.020**\n",
      "AI Sentiment:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ✅ FORWARD PREDICTIVE POWER: -0.021**\n",
      "Risk Own Adoption:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ⚠️ WEAK FORWARD PREDICTION: -0.021 (p=0.681)\n",
      "Risk External Threats:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ⚠️ WEAK FORWARD PREDICTION: -0.039 (p=0.184)\n",
      "Risk Non-Adoption:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ✅ FORWARD PREDICTIVE POWER: -0.068***\n",
      "Forward Looking:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ✅ FORWARD PREDICTIVE POWER: -0.043***\n",
      "AI Washing:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ⚠️ WEAK FORWARD PREDICTION: -0.023 (p=0.068)\n",
      "Talent Investment:\n",
      "  ✅ LIMITED REVERSE CAUSALITY\n",
      "  ✅ FORWARD PREDICTIVE POWER: -0.042**\n",
      "\n",
      "================================================================================\n",
      "\n",
      "📄 Creating comprehensive Word document...\n",
      "✅ Word document saved to: /Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/RegressionTables/EndogeneityTesting/AI_Factor_Endogeneity_Tests_Comprehensive.docx\n",
      "\n",
      "📄 Complete endogeneity analysis saved to: /Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/RegressionTables/EndogeneityTesting/AI_Factor_Endogeneity_Tests_Comprehensive.docx\n",
      "\n",
      "✅ ENDOGENEITY TESTING COMPLETED SUCCESSFULLY!\n",
      "📄 Word document saved to: /Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/RegressionTables/EndogeneityTesting/\n",
      "📊 Tables include:\n",
      "   - Table 1: Omitted Variable Bias Test\n",
      "   - Table 2: Reverse Causality Test\n",
      "   - Table 3: Coefficient Stability Test\n",
      "   - Summary and interpretation section\n",
      "   - Technical details and variable definitions\n"
     ]
    }
   ],
   "source": [
    "# ENHANCED ENDOGENEITY TESTING MODULE WITH WORD DOCUMENT EXPORT\n",
    "# ================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from docx import Document\n",
    "from docx.shared import Inches, Pt\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.table import WD_TABLE_ALIGNMENT\n",
    "from docx.oxml.shared import OxmlElement, qn\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class EndogeneityTesterWithWordExport:\n",
    "    \"\"\"\n",
    "    Enhanced endogeneity testing with professional Word document export\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path, output_path):\n",
    "        self.data_path = data_path\n",
    "        self.output_path = output_path\n",
    "        self.df = None\n",
    "        self.results = {}\n",
    "        self.diagnostics = {}\n",
    "        \n",
    "        # Core variables from your dataset\n",
    "        self.y_var = 'excess_return_12mo_annualized'\n",
    "        \n",
    "        # Standard controls available in your dataset\n",
    "        self.standard_controls_config = {\n",
    "            'Log Market Cap': 'calc_log_market_cap',\n",
    "            'Price-to-Book': 'calc_price_to_book',\n",
    "            'ROA': 'calc_roa',\n",
    "            'Market-to-Book': 'calc_market_to_book',\n",
    "            'Operating Margin': 'calc_operating_margin',\n",
    "            'Asset Turnover': 'calc_asset_turnover'\n",
    "        }\n",
    "        \n",
    "        # Management quality proxies using your data\n",
    "        self.management_proxies_config = {\n",
    "            'ROA Volatility': 'calc_roa_volatility',\n",
    "            'Return Volatility (t-1)': 'return_volatility_lag1',\n",
    "            'Return Volatility (t-2)': 'return_volatility_lag2',\n",
    "            'Past Performance (t-1m)': 'return_t_minus_1m',\n",
    "            'Past Performance (t-2m)': 'return_t_minus_2m', \n",
    "            'Past Performance (t-3m)': 'return_t_minus_3m',\n",
    "            'Debt to Assets': 'calc_debt_to_assets',\n",
    "            'Profit Margin': 'calc_profit_margin',\n",
    "            'ROE': 'calc_roe'\n",
    "        }\n",
    "        \n",
    "        # Lagged variables for reverse causality testing\n",
    "        self.lagged_performance_vars = {\n",
    "            'Lagged Return (t-1m)': 'return_t_minus_1m',\n",
    "            'Lagged Return (t-2m)': 'return_t_minus_2m',\n",
    "            'Lagged Return (t-3m)': 'return_t_minus_3m',\n",
    "            'Lagged ROA': 'calc_roa_lag1',\n",
    "            'Lagged Market Cap': 'calc_log_market_cap_lag1'\n",
    "        }\n",
    "\n",
    "    def load_and_prepare_data(self):\n",
    "        \"\"\"Load data and create management quality proxies\"\"\"\n",
    "        print(\"📊 Loading data for endogeneity testing...\")\n",
    "        self.df = pd.read_csv(self.data_path, dtype={'gvkey': str, 'CIK': str})\n",
    "        \n",
    "        # Create AI factor averages\n",
    "        self.ai_factors_config = {\n",
    "            'Strategic Depth': ['Strategic Depth_flash1_5_Numeric', 'Strategic Depth_flash2_5_Numeric', 'Strategic Depth_gpt4o_Numeric'],\n",
    "            'AI Sentiment': ['Disclosure Sentiment_flash1_5_Numeric', 'Disclosure Sentiment_flash2_5_Numeric', 'Disclosure Sentiment_gpt4o_Numeric'],\n",
    "            'Risk Own Adoption': ['Risk - Own Adoption_flash1_5_Numeric', 'Risk - Own Adoption_flash2_5_Numeric', 'Risk - Own Adoption_gpt4o_Numeric'],\n",
    "            'Risk External Threats': ['Risk - External Threats_flash1_5_Numeric', 'Risk - External Threats_flash2_5_Numeric', 'Risk - External Threats_gpt4o_Numeric'],\n",
    "            'Risk Non-Adoption': ['Risk - Non-Adoption_flash1_5_Numeric', 'Risk - Non-Adoption_flash2_5_Numeric', 'Risk - Non-Adoption_gpt4o_Numeric'],\n",
    "            'Forward Looking': ['Forward-Looking_flash1_5_Numeric', 'Forward-Looking_flash2_5_Numeric', 'Forward-Looking_gpt4o_Numeric'],\n",
    "            'AI Washing': ['AI Washing Index_flash1_5_Numeric', 'AI Washing Index_flash2_5_Numeric', 'AI Washing Index_gpt4o_Numeric'],\n",
    "            'Talent Investment': ['Talent & Investment_flash1_5_Numeric', 'Talent & Investment_flash2_5_Numeric', 'Talent & Investment_gpt4o_Numeric'],\n",
    "        }\n",
    "        \n",
    "        self.average_ai_factor_cols_map = {}\n",
    "        for factor_name, cols in self.ai_factors_config.items():\n",
    "            available_cols = [col for col in cols if col in self.df.columns]\n",
    "            if available_cols:\n",
    "                avg_col_name = f\"{factor_name.replace(' ', '_')}_Average\"\n",
    "                self.df[avg_col_name] = self.df[available_cols].mean(axis=1, skipna=True)\n",
    "                self.average_ai_factor_cols_map[factor_name] = avg_col_name\n",
    "                print(f\" Created {avg_col_name}: {self.df[avg_col_name].notna().sum():,} obs\")\n",
    "        \n",
    "        # Create management quality proxies\n",
    "        self._create_management_proxies()\n",
    "        \n",
    "        # Create additional lagged variables\n",
    "        self._create_additional_lagged_variables()\n",
    "        \n",
    "        # Create fixed effects dummies\n",
    "        self._prepare_fixed_effects_dummies()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def _create_management_proxies(self):\n",
    "        \"\"\"Create management quality proxy variables\"\"\"\n",
    "        print(\"🔧 Creating management quality proxies...\")\n",
    "        \n",
    "        # Sort by firm and year for rolling calculations\n",
    "        self.df = self.df.sort_values(['gvkey', 'Year'])\n",
    "        \n",
    "        # ROA Volatility (3-year rolling standard deviation)\n",
    "        if 'calc_roa' in self.df.columns:\n",
    "            self.df['calc_roa_volatility'] = self.df.groupby('gvkey')['calc_roa'].rolling(\n",
    "                window=3, min_periods=2\n",
    "            ).std().reset_index(0, drop=True)\n",
    "            \n",
    "            # Create lagged ROA\n",
    "            self.df['calc_roa_lag1'] = self.df.groupby('gvkey')['calc_roa'].shift(1)\n",
    "        \n",
    "        # Return Volatility using your existing return columns\n",
    "        return_cols = ['return_t_minus_1m', 'return_t_minus_2m', 'return_t_minus_3m']\n",
    "        available_return_cols = [col for col in return_cols if col in self.df.columns]\n",
    "        \n",
    "        if len(available_return_cols) >= 2:\n",
    "            # Calculate return volatility from available lagged returns\n",
    "            self.df['return_volatility_lag1'] = self.df[available_return_cols].std(axis=1, skipna=True)\n",
    "            # Create a second measure using just t-2 and t-3\n",
    "            if len(available_return_cols) >= 3:\n",
    "                self.df['return_volatility_lag2'] = self.df[available_return_cols[1:]].std(axis=1, skipna=True)\n",
    "        \n",
    "        # Create lagged market cap\n",
    "        if 'calc_log_market_cap' in self.df.columns:\n",
    "            self.df['calc_log_market_cap_lag1'] = self.df.groupby('gvkey')['calc_log_market_cap'].shift(1)\n",
    "        \n",
    "        print(\" Management quality proxies created\")\n",
    "\n",
    "    def _create_additional_lagged_variables(self):\n",
    "        \"\"\"Create additional lagged variables for robustness\"\"\"\n",
    "        print(\"🔧 Creating additional lagged variables...\")\n",
    "        \n",
    "        # Create lagged versions of key financial variables\n",
    "        vars_to_lag = ['calc_price_to_book', 'calc_market_to_book', 'calc_operating_margin']\n",
    "        \n",
    "        for var in vars_to_lag:\n",
    "            if var in self.df.columns:\n",
    "                self.df[f'{var}_lag1'] = self.df.groupby('gvkey')[var].shift(1)\n",
    "        \n",
    "        print(\" Additional lagged variables created\")\n",
    "\n",
    "    def _prepare_fixed_effects_dummies(self):\n",
    "        \"\"\"Create fixed effects dummy variables\"\"\"\n",
    "        # Year fixed effects\n",
    "        self.master_year_fe_cols = []\n",
    "        if 'Year' in self.df.columns:\n",
    "            valid_years = sorted(self.df['Year'].dropna().unique())\n",
    "            if len(valid_years) > 1:\n",
    "                for year_val in valid_years[1:]:  # Drop first year as base\n",
    "                    fe_col_name = f'year_{int(year_val)}'\n",
    "                    self.df[fe_col_name] = (self.df['Year'] == year_val).astype(int)\n",
    "                    self.master_year_fe_cols.append(fe_col_name)\n",
    "        \n",
    "        # Sector fixed effects\n",
    "        self.master_sector_fe_cols = []\n",
    "        sector_col = 'Sector'\n",
    "        \n",
    "        if sector_col in self.df.columns:\n",
    "            valid_sectors = self.df[sector_col].dropna().unique()\n",
    "            if len(valid_sectors) > 1:\n",
    "                for i, sector_val in enumerate(valid_sectors[1:]):  # Drop first sector as base\n",
    "                    clean_sector_val = str(sector_val).replace(' ', '_').replace('&', 'and').replace('/', '_').replace('-', '_')\n",
    "                    fe_col_name = f'sector_{clean_sector_val}_{i}'\n",
    "                    self.df[fe_col_name] = (self.df[sector_col] == sector_val).astype(int)\n",
    "                    self.master_sector_fe_cols.append(fe_col_name)\n",
    "\n",
    "    def _run_regression_with_controls(self, y_var, x_vars, control_vars=None, include_fe=True):\n",
    "        \"\"\"Helper function to run regression with specified controls\"\"\"\n",
    "        if control_vars is None:\n",
    "            control_vars = []\n",
    "        \n",
    "        # Combine all variables\n",
    "        all_x_vars = x_vars.copy()\n",
    "        all_x_vars.extend(control_vars)\n",
    "        \n",
    "        if include_fe:\n",
    "            all_x_vars.extend(self.master_year_fe_cols)\n",
    "            all_x_vars.extend(self.master_sector_fe_cols)\n",
    "        \n",
    "        # Filter to available columns\n",
    "        all_x_vars = [var for var in all_x_vars if var in self.df.columns]\n",
    "        all_x_vars = list(set(all_x_vars))  # Remove duplicates\n",
    "        \n",
    "        # Prepare regression data\n",
    "        required_cols = [y_var] + all_x_vars + ['gvkey']\n",
    "        reg_data = self.df[required_cols].dropna()\n",
    "        \n",
    "        if len(reg_data) < len(all_x_vars) + 20:  # Need sufficient observations\n",
    "            return None\n",
    "        \n",
    "        # Winsorize variables\n",
    "        vars_to_winsorize = [y_var] + all_x_vars\n",
    "        for var in vars_to_winsorize:\n",
    "            if pd.api.types.is_numeric_dtype(reg_data[var]):\n",
    "                if reg_data[var].notna().sum() > 0 and reg_data[var].nunique() > 1:\n",
    "                    p1, p99 = reg_data[var].quantile([0.01, 0.99])\n",
    "                    if pd.notna(p1) and pd.notna(p99) and p1 != p99:\n",
    "                        reg_data[var] = reg_data[var].clip(lower=p1, upper=p99)\n",
    "        \n",
    "        # Run regression\n",
    "        try:\n",
    "            X = sm.add_constant(reg_data[all_x_vars])\n",
    "            y = reg_data[y_var]\n",
    "            model = OLS(y, X).fit(cov_type='cluster', cov_kwds={'groups': reg_data['gvkey']})\n",
    "            return model\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def test_omitted_variable_bias(self):\n",
    "        \"\"\"Test for omitted variable bias using management quality proxies\"\"\"\n",
    "        print(\"\\n🔬 Testing for Omitted Variable Bias...\")\n",
    "        \n",
    "        self.results['omitted_variable_bias'] = {}\n",
    "        \n",
    "        # Get available standard controls\n",
    "        std_controls = [col for col in self.standard_controls_config.values() \n",
    "                       if col and col in self.df.columns]\n",
    "        \n",
    "        # Get available management proxies\n",
    "        mgmt_proxies = [col for col in self.management_proxies_config.values() \n",
    "                       if col and col in self.df.columns]\n",
    "        \n",
    "        print(f\"Available standard controls: {len(std_controls)}\")\n",
    "        print(f\"Available management proxies: {len(mgmt_proxies)}\")\n",
    "        \n",
    "        for ai_factor_name, ai_col in self.average_ai_factor_cols_map.items():\n",
    "            if ai_col not in self.df.columns:\n",
    "                continue\n",
    "                \n",
    "            factor_results = {}\n",
    "            \n",
    "            # Model 1: Baseline (AI factor + standard controls + FE)\n",
    "            model_baseline = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=std_controls,\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_baseline:\n",
    "                factor_results['Baseline'] = model_baseline\n",
    "            \n",
    "            # Model 2: Add management quality proxies\n",
    "            model_with_mgmt = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=std_controls + mgmt_proxies,\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_with_mgmt:\n",
    "                factor_results['With Management Proxies'] = model_with_mgmt\n",
    "            \n",
    "            # Model 3: Only management proxies\n",
    "            model_mgmt_only = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=mgmt_proxies,\n",
    "                control_vars=std_controls,\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_mgmt_only:\n",
    "                factor_results['Management Proxies Only'] = model_mgmt_only\n",
    "            \n",
    "            if factor_results:\n",
    "                self.results['omitted_variable_bias'][ai_factor_name] = factor_results\n",
    "                \n",
    "                # Print coefficient comparison for this factor\n",
    "                if 'Baseline' in factor_results and 'With Management Proxies' in factor_results:\n",
    "                    baseline_coef = factor_results['Baseline'].params.get(ai_col, np.nan)\n",
    "                    mgmt_coef = factor_results['With Management Proxies'].params.get(ai_col, np.nan)\n",
    "                    \n",
    "                    if not np.isnan(baseline_coef) and not np.isnan(mgmt_coef) and baseline_coef != 0:\n",
    "                        pct_change = ((mgmt_coef - baseline_coef) / abs(baseline_coef)) * 100\n",
    "                        print(f\"  {ai_factor_name}: {baseline_coef:.3f} → {mgmt_coef:.3f} ({pct_change:+.1f}%)\")\n",
    "        \n",
    "        print(\" Omitted Variable Bias testing complete\")\n",
    "\n",
    "    def test_reverse_causality(self):\n",
    "        \"\"\"Test for reverse causality by regressing AI metrics on lagged performance\"\"\"\n",
    "        print(\"\\n🔬 Testing for Reverse Causality...\")\n",
    "        \n",
    "        self.results['reverse_causality'] = {}\n",
    "        \n",
    "        # Get available lagged performance variables\n",
    "        lagged_perf_vars = [col for col in self.lagged_performance_vars.values() \n",
    "                           if col and col in self.df.columns]\n",
    "        \n",
    "        # Get available standard controls\n",
    "        std_controls = [col for col in self.standard_controls_config.values() \n",
    "                       if col and col in self.df.columns]\n",
    "        \n",
    "        print(f\"Available lagged performance vars: {lagged_perf_vars}\")\n",
    "        \n",
    "        for ai_factor_name, ai_col in self.average_ai_factor_cols_map.items():\n",
    "            if ai_col not in self.df.columns:\n",
    "                continue\n",
    "                \n",
    "            factor_results = {}\n",
    "            \n",
    "            # Test 1: AI factor regressed on lagged returns\n",
    "            lagged_return_vars = [col for col in lagged_perf_vars \n",
    "                                 if 'return_t_minus' in col or 'calc_roa' in col]\n",
    "            \n",
    "            if lagged_return_vars:\n",
    "                model_reverse_main = self._run_regression_with_controls(\n",
    "                    y_var=ai_col,\n",
    "                    x_vars=lagged_return_vars,\n",
    "                    control_vars=[],\n",
    "                    include_fe=True\n",
    "                )\n",
    "                if model_reverse_main:\n",
    "                    factor_results['AI ~ Lagged Performance'] = model_reverse_main\n",
    "            \n",
    "            # Test 2: AI factor regressed on lagged returns + controls\n",
    "            if lagged_return_vars:\n",
    "                model_reverse_controls = self._run_regression_with_controls(\n",
    "                    y_var=ai_col,\n",
    "                    x_vars=lagged_return_vars,\n",
    "                    control_vars=std_controls,\n",
    "                    include_fe=True\n",
    "                )\n",
    "                if model_reverse_controls:\n",
    "                    factor_results['AI ~ Lagged Performance + Controls'] = model_reverse_controls\n",
    "            \n",
    "            # Test 3: Forward-looking test - current performance on lagged AI\n",
    "            ai_col_lag1 = f'{ai_col}_lag1'\n",
    "            if ai_col_lag1 not in self.df.columns:\n",
    "                self.df[ai_col_lag1] = self.df.groupby('gvkey')[ai_col].shift(1)\n",
    "            \n",
    "            if ai_col_lag1 in self.df.columns:\n",
    "                model_forward = self._run_regression_with_controls(\n",
    "                    y_var=self.y_var,\n",
    "                    x_vars=[ai_col_lag1],\n",
    "                    control_vars=std_controls,\n",
    "                    include_fe=True\n",
    "                )\n",
    "                if model_forward:\n",
    "                    factor_results['Current Return ~ Lagged AI'] = model_forward\n",
    "            \n",
    "            if factor_results:\n",
    "                self.results['reverse_causality'][ai_factor_name] = factor_results\n",
    "        \n",
    "        print(\" Reverse Causality testing complete\")\n",
    "\n",
    "    def test_coefficient_stability(self):\n",
    "        \"\"\"Test coefficient stability across different specifications\"\"\"\n",
    "        print(\"\\n🔬 Testing Coefficient Stability...\")\n",
    "        \n",
    "        self.results['coefficient_stability'] = {}\n",
    "        \n",
    "        std_controls = [col for col in self.standard_controls_config.values() \n",
    "                       if col and col in self.df.columns]\n",
    "        mgmt_proxies = [col for col in self.management_proxies_config.values() \n",
    "                       if col and col in self.df.columns]\n",
    "        \n",
    "        for ai_factor_name, ai_col in self.average_ai_factor_cols_map.items():\n",
    "            if ai_col not in self.df.columns:\n",
    "                continue\n",
    "                \n",
    "            factor_results = {}\n",
    "            \n",
    "            # Specification 1: AI factor only + FE\n",
    "            model_fe_only = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=[],\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_fe_only:\n",
    "                factor_results['FE Only'] = model_fe_only\n",
    "            \n",
    "            # Specification 2: + Standard controls\n",
    "            model_std = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=std_controls,\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_std:\n",
    "                factor_results['+ Standard Controls'] = model_std\n",
    "            \n",
    "            # Specification 3: + Management proxies\n",
    "            model_mgmt = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=std_controls + mgmt_proxies,\n",
    "                include_fe=True\n",
    "            )\n",
    "            if model_mgmt:\n",
    "                factor_results['+ Management Proxies'] = model_mgmt\n",
    "            \n",
    "            # Specification 4: No fixed effects\n",
    "            model_no_fe = self._run_regression_with_controls(\n",
    "                y_var=self.y_var,\n",
    "                x_vars=[ai_col],\n",
    "                control_vars=std_controls,\n",
    "                include_fe=False\n",
    "            )\n",
    "            if model_no_fe:\n",
    "                factor_results['No Fixed Effects'] = model_no_fe\n",
    "            \n",
    "            if factor_results:\n",
    "                self.results['coefficient_stability'][ai_factor_name] = factor_results\n",
    "        \n",
    "        print(\" Coefficient Stability testing complete\")\n",
    "\n",
    "    def run_all_endogeneity_tests(self):\n",
    "        \"\"\"Run all endogeneity tests\"\"\"\n",
    "        print(\"\\n🚀 Running comprehensive endogeneity testing...\")\n",
    "        \n",
    "        self.test_omitted_variable_bias()\n",
    "        self.test_reverse_causality()\n",
    "        self.test_coefficient_stability()\n",
    "        \n",
    "        print(\"All endogeneity tests complete\")\n",
    "        return self\n",
    "\n",
    "    def _get_significance_stars(self, pvalue):\n",
    "        \"\"\"Get significance stars for p-values\"\"\"\n",
    "        if pd.isna(pvalue):\n",
    "            return \"\"\n",
    "        if pvalue < 0.01:\n",
    "            return \"***\"\n",
    "        elif pvalue < 0.05:\n",
    "            return \"**\"\n",
    "        elif pvalue < 0.10:\n",
    "            return \"*\"\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def _set_table_borders(self, table):\n",
    "        \"\"\"Add professional borders to table\"\"\"\n",
    "        tbl = table._tbl\n",
    "        tblBorders = OxmlElement('w:tblBorders')\n",
    "        \n",
    "        for border_name in ['top', 'left', 'bottom', 'right', 'insideH', 'insideV']:\n",
    "            border = OxmlElement(f'w:{border_name}')\n",
    "            border.set(qn('w:val'), 'single')\n",
    "            border.set(qn('w:sz'), '4')\n",
    "            border.set(qn('w:space'), '0')\n",
    "            border.set(qn('w:color'), '000000')\n",
    "            tblBorders.append(border)\n",
    "        \n",
    "        tbl.tblPr.append(tblBorders)\n",
    "\n",
    "    def create_word_document(self):\n",
    "        \"\"\"Create comprehensive Word document with all endogeneity test results\"\"\"\n",
    "        print(\"\\n Creating comprehensive Word document...\")\n",
    "        \n",
    "        doc = Document()\n",
    "        \n",
    "        # Add title\n",
    "        title = doc.add_heading('Endogeneity Testing Results', 0)\n",
    "        title.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        \n",
    "        # Add summary paragraph\n",
    "        summary = doc.add_paragraph()\n",
    "        summary.add_run(\"Summary: \").bold = True\n",
    "        summary.add_run(\"This document presents comprehensive endogeneity testing results for AI factors in corporate disclosure analysis. \"\n",
    "                       \"Tests include omitted variable bias detection using management quality proxies, reverse causality analysis \"\n",
    "                       \"through lagged performance variables, and coefficient stability assessment across multiple specifications.\")\n",
    "        \n",
    "        doc.add_page_break()\n",
    "        \n",
    "        # Table 1: Omitted Variable Bias Test\n",
    "        doc.add_heading('Table 1: Omitted Variable Bias Test', level=1)\n",
    "        \n",
    "        ovb_para = doc.add_paragraph()\n",
    "        ovb_para.add_run(\"This table tests whether AI factor coefficients remain stable when management quality proxies are added as controls. \"\n",
    "                        \"Large coefficient changes suggest potential omitted variable bias.\")\n",
    "        \n",
    "        if 'omitted_variable_bias' in self.results:\n",
    "            # Create table\n",
    "            table = doc.add_table(rows=1, cols=6)\n",
    "            table.style = 'Table Grid'\n",
    "            self._set_table_borders(table)\n",
    "            \n",
    "            # Header row\n",
    "            hdr_cells = table.rows[0].cells\n",
    "            headers = ['AI Factor', 'Baseline Coef.', 'Baseline p-val', 'With Mgmt Proxies Coef.', 'With Mgmt p-val', 'Change (%)']\n",
    "            for i, header in enumerate(headers):\n",
    "                hdr_cells[i].text = header\n",
    "                hdr_cells[i].paragraphs[0].runs[0].bold = True\n",
    "                hdr_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            \n",
    "            # Data rows\n",
    "            for ai_factor, results in self.results['omitted_variable_bias'].items():\n",
    "                if 'Baseline' in results and 'With Management Proxies' in results:\n",
    "                    baseline_model = results['Baseline']\n",
    "                    mgmt_model = results['With Management Proxies']\n",
    "                    \n",
    "                    ai_col = self.average_ai_factor_cols_map.get(ai_factor)\n",
    "                    if ai_col and ai_col in baseline_model.params and ai_col in mgmt_model.params:\n",
    "                        baseline_coef = baseline_model.params[ai_col]\n",
    "                        mgmt_coef = mgmt_model.params[ai_col]\n",
    "                        baseline_pval = baseline_model.pvalues[ai_col]\n",
    "                        mgmt_pval = mgmt_model.pvalues[ai_col]\n",
    "                        \n",
    "                        if baseline_coef != 0:\n",
    "                            pct_change = ((mgmt_coef - baseline_coef) / abs(baseline_coef)) * 100\n",
    "                            \n",
    "                            row_cells = table.add_row().cells\n",
    "                            row_cells[0].text = ai_factor\n",
    "                            row_cells[1].text = f\"{baseline_coef:.3f}{self._get_significance_stars(baseline_pval)}\"\n",
    "                            row_cells[2].text = f\"{baseline_pval:.3f}\"\n",
    "                            row_cells[3].text = f\"{mgmt_coef:.3f}{self._get_significance_stars(mgmt_pval)}\"\n",
    "                            row_cells[4].text = f\"{mgmt_pval:.3f}\"\n",
    "                            row_cells[5].text = f\"{pct_change:+.1f}%\"\n",
    "                            \n",
    "                            # Center align numeric columns\n",
    "                            for i in range(1, 6):\n",
    "                                row_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        \n",
    "        doc.add_paragraph()\n",
    "        doc.add_paragraph(\"Note: ***, **, * indicate significance at 1%, 5%, and 10% levels respectively. \"\n",
    "                         \"Changes <25% suggest robust coefficients.\")\n",
    "        \n",
    "        doc.add_page_break()\n",
    "        \n",
    "        # Table 2: Reverse Causality Test\n",
    "        doc.add_heading('Table 2: Reverse Causality Test', level=1)\n",
    "        \n",
    "        rc_para = doc.add_paragraph()\n",
    "        rc_para.add_run(\"This table examines whether AI factors are influenced by past performance (reverse causality) \"\n",
    "                       \"and tests forward predictive power using lagged AI metrics.\")\n",
    "        \n",
    "        if 'reverse_causality' in self.results:\n",
    "            # Create table\n",
    "            table = doc.add_table(rows=1, cols=5)\n",
    "            table.style = 'Table Grid'\n",
    "            self._set_table_borders(table)\n",
    "            \n",
    "            # Header row\n",
    "            hdr_cells = table.rows[0].cells\n",
    "            headers = ['AI Factor', 'Reverse Causality', 'F-statistic', 'Forward Predictive Power', 'Forward p-value']\n",
    "            for i, header in enumerate(headers):\n",
    "                hdr_cells[i].text = header\n",
    "                hdr_cells[i].paragraphs[0].runs[0].bold = True\n",
    "                hdr_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            \n",
    "            # Data rows\n",
    "            for ai_factor, results in self.results['reverse_causality'].items():\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = ai_factor\n",
    "                \n",
    "                # Check for reverse causality\n",
    "                if 'AI ~ Lagged Performance' in results:\n",
    "                    model = results['AI ~ Lagged Performance']\n",
    "                    significant_lags = []\n",
    "                    \n",
    "                    for param_name in model.params.index:\n",
    "                        if 'return_t_minus' in param_name or 'lag' in param_name.lower():\n",
    "                            if param_name != 'const':\n",
    "                                pval = model.pvalues[param_name]\n",
    "                                if pval < 0.05:\n",
    "                                    significant_lags.append(param_name)\n",
    "                    \n",
    "                    if significant_lags:\n",
    "                        row_cells[1].text = \" Detected\"\n",
    "                        try:\n",
    "                            row_cells[2].text = f\"{model.fvalue:.2f}\"\n",
    "                        except:\n",
    "                            row_cells[2].text = \"N/A\"\n",
    "                    else:\n",
    "                        row_cells[1].text = \" Limited\"\n",
    "                        try:\n",
    "                            row_cells[2].text = f\"{model.fvalue:.2f}\"\n",
    "                        except:\n",
    "                            row_cells[2].text = \"N/A\"\n",
    "                \n",
    "                # Check forward predictive power\n",
    "                if 'Current Return ~ Lagged AI' in results:\n",
    "                    model = results['Current Return ~ Lagged AI']\n",
    "                    ai_col_lag = f\"{self.average_ai_factor_cols_map.get(ai_factor)}_lag1\"\n",
    "                    \n",
    "                    if ai_col_lag in model.params:\n",
    "                        pval = model.pvalues[ai_col_lag]\n",
    "                        coef = model.params[ai_col_lag]\n",
    "                        stars = self._get_significance_stars(pval)\n",
    "                        \n",
    "                        row_cells[3].text = f\"{coef:.3f}{stars}\"\n",
    "                        row_cells[4].text = f\"{pval:.3f}\"\n",
    "                \n",
    "                # Center align\n",
    "                for i in range(1, 5):\n",
    "                    row_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        \n",
    "        doc.add_paragraph()\n",
    "        doc.add_paragraph(\"Note: Reverse causality test examines whether lagged performance predicts current AI metrics. \"\n",
    "                         \"Forward predictive power tests whether lagged AI metrics predict current returns.\")\n",
    "        \n",
    "        doc.add_page_break()\n",
    "        \n",
    "        # Table 3: Coefficient Stability Test\n",
    "        doc.add_heading('Table 3: Coefficient Stability Across Specifications', level=1)\n",
    "        \n",
    "        cs_para = doc.add_paragraph()\n",
    "        cs_para.add_run(\"This table shows how AI factor coefficients change across different regression specifications. \"\n",
    "                       \"Stable coefficients suggest robust relationships.\")\n",
    "        \n",
    "        if 'coefficient_stability' in self.results:\n",
    "            # Create table\n",
    "            table = doc.add_table(rows=1, cols=6)\n",
    "            table.style = 'Table Grid'\n",
    "            self._set_table_borders(table)\n",
    "            \n",
    "            # Header row\n",
    "            hdr_cells = table.rows[0].cells\n",
    "            headers = ['AI Factor', 'FE Only', '+ Standard Controls', '+ Management Proxies', 'No Fixed Effects', 'Stability Score']\n",
    "            for i, header in enumerate(headers):\n",
    "                hdr_cells[i].text = header\n",
    "                hdr_cells[i].paragraphs[0].runs[0].bold = True\n",
    "                hdr_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "            \n",
    "            # Data rows\n",
    "            for ai_factor, results in self.results['coefficient_stability'].items():\n",
    "                row_cells = table.add_row().cells\n",
    "                row_cells[0].text = ai_factor\n",
    "                \n",
    "                ai_col = self.average_ai_factor_cols_map.get(ai_factor)\n",
    "                coefficients = {}\n",
    "                \n",
    "                # Extract coefficients from each specification\n",
    "                for spec_name, model in results.items():\n",
    "                    if ai_col and ai_col in model.params:\n",
    "                        coef = model.params[ai_col]\n",
    "                        pval = model.pvalues[ai_col]\n",
    "                        stars = self._get_significance_stars(pval)\n",
    "                        coefficients[spec_name] = f\"{coef:.3f}{stars}\"\n",
    "                \n",
    "                # Fill in the coefficients\n",
    "                spec_order = ['FE Only', '+ Standard Controls', '+ Management Proxies', 'No Fixed Effects']\n",
    "                for i, spec in enumerate(spec_order, 1):\n",
    "                    if spec in coefficients:\n",
    "                        row_cells[i].text = coefficients[spec]\n",
    "                    else:\n",
    "                        row_cells[i].text = \"N/A\"\n",
    "                    row_cells[i].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "                \n",
    "                # Calculate stability score (between FE Only and Full Controls)\n",
    "                if 'FE Only' in results and '+ Management Proxies' in results:\n",
    "                    fe_coef = results['FE Only'].params.get(ai_col, np.nan)\n",
    "                    mgmt_coef = results['+ Management Proxies'].params.get(ai_col, np.nan)\n",
    "                    \n",
    "                    if not np.isnan(fe_coef) and not np.isnan(mgmt_coef) and fe_coef != 0:\n",
    "                        pct_change = abs((mgmt_coef - fe_coef) / fe_coef) * 100\n",
    "                        stability = 100 - pct_change\n",
    "                        \n",
    "                        if stability >= 75:\n",
    "                            row_cells[5].text = f\"{stability:.1f}%\"\n",
    "                        else:\n",
    "                            row_cells[5].text = f\"{stability:.1f}% \"\n",
    "                    else:\n",
    "                        row_cells[5].text = \"N/A\"\n",
    "                else:\n",
    "                    row_cells[5].text = \"N/A\"\n",
    "                \n",
    "                row_cells[5].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "        \n",
    "        doc.add_paragraph()\n",
    "        doc.add_paragraph(\"Note: Stability Score shows percentage stability between FE Only and Full Controls specifications. \"\n",
    "                         \"Scores ≥75% indicate robust coefficients.\")\n",
    "        \n",
    "        doc.add_page_break()\n",
    "        \n",
    "        # Summary and Interpretation\n",
    "        doc.add_heading('Summary and Interpretation', level=1)\n",
    "        \n",
    "        # Overall assessment\n",
    "        doc.add_heading('Overall Assessment', level=2)\n",
    "        \n",
    "        robust_factors = []\n",
    "        concern_factors = []\n",
    "        \n",
    "        if 'omitted_variable_bias' in self.results:\n",
    "            for ai_factor, results in self.results['omitted_variable_bias'].items():\n",
    "                if 'Baseline' in results and 'With Management Proxies' in results:\n",
    "                    baseline_model = results['Baseline']\n",
    "                    mgmt_model = results['With Management Proxies']\n",
    "                    \n",
    "                    ai_col = self.average_ai_factor_cols_map.get(ai_factor)\n",
    "                    if ai_col and ai_col in baseline_model.params and ai_col in mgmt_model.params:\n",
    "                        baseline_coef = baseline_model.params[ai_col]\n",
    "                        mgmt_coef = mgmt_model.params[ai_col]\n",
    "                        \n",
    "                        if baseline_coef != 0:\n",
    "                            pct_change = abs((mgmt_coef - baseline_coef) / baseline_coef) * 100\n",
    "                            \n",
    "                            if pct_change < 25:\n",
    "                                robust_factors.append(ai_factor)\n",
    "                            else:\n",
    "                                concern_factors.append(ai_factor)\n",
    "        \n",
    "        assessment_para = doc.add_paragraph()\n",
    "        assessment_para.add_run(\"Robust Factors: \").bold = True\n",
    "        if robust_factors:\n",
    "            assessment_para.add_run(f\"{len(robust_factors)} out of {len(self.average_ai_factor_cols_map)} AI factors demonstrate robust coefficients \"\n",
    "                                  f\"with minimal sensitivity to omitted variable bias: {', '.join(robust_factors)}.\")\n",
    "        else:\n",
    "            assessment_para.add_run(\"No factors show complete robustness.\")\n",
    "        \n",
    "        if concern_factors:\n",
    "            concern_para = doc.add_paragraph()\n",
    "            concern_para.add_run(\"Factors Requiring Attention: \").bold = True\n",
    "            concern_para.add_run(f\"The following factors show coefficient instability (>25% change): {', '.join(concern_factors)}. \"\n",
    "                               \"Consider using the more conservative estimates from full specifications.\")\n",
    "        \n",
    "        # Reverse causality assessment\n",
    "        rc_assess_para = doc.add_paragraph()\n",
    "        rc_assess_para.add_run(\"Reverse Causality: \").bold = True\n",
    "        \n",
    "        reverse_causality_detected = False\n",
    "        forward_predictive_factors = []\n",
    "        \n",
    "        if 'reverse_causality' in self.results:\n",
    "            for ai_factor, results in self.results['reverse_causality'].items():\n",
    "                if 'AI ~ Lagged Performance' in results:\n",
    "                    model = results['AI ~ Lagged Performance']\n",
    "                    significant_lags = []\n",
    "                    \n",
    "                    for param_name in model.params.index:\n",
    "                        if 'return_t_minus' in param_name or 'lag' in param_name.lower():\n",
    "                            if param_name != 'const':\n",
    "                                pval = model.pvalues[param_name]\n",
    "                                if pval < 0.05:\n",
    "                                    significant_lags.append(param_name)\n",
    "                    \n",
    "                    if significant_lags:\n",
    "                        reverse_causality_detected = True\n",
    "                \n",
    "                if 'Current Return ~ Lagged AI' in results:\n",
    "                    model = results['Current Return ~ Lagged AI']\n",
    "                    ai_col_lag = f\"{self.average_ai_factor_cols_map.get(ai_factor)}_lag1\"\n",
    "                    \n",
    "                    if ai_col_lag in model.params:\n",
    "                        pval = model.pvalues[ai_col_lag]\n",
    "                        if pval < 0.05:\n",
    "                            forward_predictive_factors.append(ai_factor)\n",
    "        \n",
    "        if not reverse_causality_detected:\n",
    "            rc_assess_para.add_run(\"Limited evidence of reverse causality across AI factors, supporting causal interpretation. \")\n",
    "        else:\n",
    "            rc_assess_para.add_run(\"Some evidence of reverse causality detected. Exercise caution in causal interpretation. \")\n",
    "        \n",
    "        if forward_predictive_factors:\n",
    "            rc_assess_para.add_run(f\"Strong forward predictive power demonstrated by: {', '.join(forward_predictive_factors)}.\")\n",
    "        \n",
    "        # Methodological implications\n",
    "        doc.add_heading('Methodological Implications', level=2)\n",
    "        \n",
    "        method_para = doc.add_paragraph()\n",
    "        method_para.add_run(\"1. Specification Choice: \").bold = True\n",
    "        method_para.add_run(\"Use full specification results (with management proxies) as primary estimates to address potential omitted variable bias.\")\n",
    "        \n",
    "        method_para2 = doc.add_paragraph()\n",
    "        method_para2.add_run(\"2. Causal Interpretation: \").bold = True\n",
    "        if not reverse_causality_detected:\n",
    "            method_para2.add_run(\"Limited reverse causality supports treating AI factors as leading indicators of future performance.\")\n",
    "        else:\n",
    "            method_para2.add_run(\"Some reverse causality detected; frame results as predictive associations rather than causal effects.\")\n",
    "        \n",
    "        method_para3 = doc.add_paragraph()\n",
    "        method_para3.add_run(\"3. Robustness: \").bold = True\n",
    "        if len(robust_factors) >= len(concern_factors):\n",
    "            method_para3.add_run(\"Majority of factors demonstrate coefficient stability, supporting the reliability of main findings.\")\n",
    "        else:\n",
    "            method_para3.add_run(\"Mixed coefficient stability suggests need for careful interpretation and conservative estimates.\")\n",
    "        \n",
    "        # Technical details\n",
    "        doc.add_page_break()\n",
    "        doc.add_heading('Technical Details and Variable Definitions', level=1)\n",
    "        \n",
    "        # Control variables\n",
    "        doc.add_heading('Control Variables Used', level=2)\n",
    "        \n",
    "        controls_para = doc.add_paragraph()\n",
    "        controls_para.add_run(\"Standard Controls: \").bold = True\n",
    "        std_controls_list = list(self.standard_controls_config.keys())\n",
    "        controls_para.add_run(f\"{', '.join(std_controls_list)}.\")\n",
    "        \n",
    "        mgmt_para = doc.add_paragraph()\n",
    "        mgmt_para.add_run(\"Management Quality Proxies: \").bold = True\n",
    "        mgmt_proxies_list = list(self.management_proxies_config.keys())\n",
    "        mgmt_para.add_run(f\"{', '.join(mgmt_proxies_list)}.\")\n",
    "        \n",
    "        # Fixed effects\n",
    "        fe_para = doc.add_paragraph()\n",
    "        fe_para.add_run(\"Fixed Effects: \").bold = True\n",
    "        fe_para.add_run(f\"Year fixed effects ({len(self.master_year_fe_cols)} dummies) and \"\n",
    "                       f\"Sector fixed effects ({len(self.master_sector_fe_cols)} dummies) included in all specifications.\")\n",
    "        \n",
    "        # Sample information\n",
    "        doc.add_heading('Sample Information', level=2)\n",
    "        \n",
    "        sample_para = doc.add_paragraph()\n",
    "        sample_para.add_run(\"Dataset: \").bold = True\n",
    "        sample_para.add_run(f\"Russell 3000 companies, 2020-2024 panel. Total observations: {len(self.df):,}.\")\n",
    "        \n",
    "        winsor_para = doc.add_paragraph()\n",
    "        winsor_para.add_run(\"Data Treatment: \").bold = True\n",
    "        winsor_para.add_run(\"All continuous variables winsorized at 1st and 99th percentiles. \"\n",
    "                           \"Standard errors clustered by firm (gvkey).\")\n",
    "        \n",
    "        # Footer\n",
    "        doc.add_paragraph()\n",
    "        footer_para = doc.add_paragraph()\n",
    "        footer_para.add_run(\"Generated by: \").italic = True\n",
    "        footer_para.add_run(\"AI Factor Endogeneity Testing Module\").italic = True\n",
    "        \n",
    "        return doc\n",
    "\n",
    "    def save_word_document(self, filename=None):\n",
    "        \"\"\"Save the Word document to specified path\"\"\"\n",
    "        if filename is None:\n",
    "            filename = os.path.join(self.output_path, \"AI_Factor_Endogeneity_Tests_Comprehensive.docx\")\n",
    "        \n",
    "        doc = self.create_word_document()\n",
    "        \n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "        \n",
    "        doc.save(filename)\n",
    "        print(f\" Word document saved to: {filename}\")\n",
    "        return filename\n",
    "\n",
    "    def print_summary_results(self):\n",
    "        \"\"\"Print comprehensive summary of endogeneity test results\"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\" ENDOGENEITY TESTING SUMMARY\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Omitted Variable Bias Summary\n",
    "        if 'omitted_variable_bias' in self.results:\n",
    "            print(\"\\n1. OMITTED VARIABLE BIAS TEST:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for ai_factor, results in self.results['omitted_variable_bias'].items():\n",
    "                if 'Baseline' in results and 'With Management Proxies' in results:\n",
    "                    baseline_model = results['Baseline']\n",
    "                    mgmt_model = results['With Management Proxies']\n",
    "                    \n",
    "                    ai_col = self.average_ai_factor_cols_map.get(ai_factor)\n",
    "                    if ai_col and ai_col in baseline_model.params and ai_col in mgmt_model.params:\n",
    "                        baseline_coef = baseline_model.params[ai_col]\n",
    "                        mgmt_coef = mgmt_model.params[ai_col]\n",
    "                        baseline_pval = baseline_model.pvalues[ai_col]\n",
    "                        mgmt_pval = mgmt_model.pvalues[ai_col]\n",
    "                        \n",
    "                        if baseline_coef != 0:\n",
    "                            pct_change = ((mgmt_coef - baseline_coef) / abs(baseline_coef)) * 100\n",
    "                            baseline_stars = self._get_significance_stars(baseline_pval)\n",
    "                            mgmt_stars = self._get_significance_stars(mgmt_pval)\n",
    "                            \n",
    "                            print(f\"{ai_factor}:\")\n",
    "                            print(f\"  Baseline: {baseline_coef:.3f}{baseline_stars}\")\n",
    "                            print(f\"  With mgmt proxies: {mgmt_coef:.3f}{mgmt_stars}\")\n",
    "                            print(f\"  Change: {pct_change:+.1f}%\")\n",
    "                            \n",
    "                            if abs(pct_change) < 25:\n",
    "                                print(f\"  Assessment: ROBUST (small change)\")\n",
    "                            else:\n",
    "                                print(f\"  Assessment:  POTENTIAL BIAS (large change)\")\n",
    "        \n",
    "        # Reverse Causality Summary\n",
    "        if 'reverse_causality' in self.results:\n",
    "            print(\"\\n2. REVERSE CAUSALITY TEST:\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            for ai_factor, results in self.results['reverse_causality'].items():\n",
    "                print(f\"{ai_factor}:\")\n",
    "                \n",
    "                if 'AI ~ Lagged Performance' in results:\n",
    "                    model = results['AI ~ Lagged Performance']\n",
    "                    significant_lags = []\n",
    "                    \n",
    "                    for param_name in model.params.index:\n",
    "                        if 'return_t_minus' in param_name or 'lag' in param_name.lower():\n",
    "                            if param_name != 'const':\n",
    "                                pval = model.pvalues[param_name]\n",
    "                                if pval < 0.05:\n",
    "                                    coef = model.params[param_name]\n",
    "                                    stars = self._get_significance_stars(pval)\n",
    "                                    significant_lags.append(f\"{param_name}: {coef:.3f}{stars}\")\n",
    "                    \n",
    "                    if significant_lags:\n",
    "                        print(f\"   REVERSE CAUSALITY CONCERN:\")\n",
    "                        for lag in significant_lags:\n",
    "                            print(f\"    {lag}\")\n",
    "                    else:\n",
    "                        print(f\"   LIMITED REVERSE CAUSALITY\")\n",
    "                \n",
    "                if 'Current Return ~ Lagged AI' in results:\n",
    "                    model = results['Current Return ~ Lagged AI']\n",
    "                    ai_col_lag = f\"{self.average_ai_factor_cols_map.get(ai_factor)}_lag1\"\n",
    "                    \n",
    "                    if ai_col_lag in model.params:\n",
    "                        pval = model.pvalues[ai_col_lag]\n",
    "                        coef = model.params[ai_col_lag]\n",
    "                        stars = self._get_significance_stars(pval)\n",
    "                        \n",
    "                        if pval < 0.05:\n",
    "                            print(f\" FORWARD PREDICTIVE POWER: {coef:.3f}{stars}\")\n",
    "                        else:\n",
    "                            print(f\"  WEAK FORWARD PREDICTION: {coef:.3f} (p={pval:.3f})\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "    def run_complete_endogeneity_analysis(self):\n",
    "        \"\"\"Run complete endogeneity analysis and create Word document\"\"\"\n",
    "        print(\" RUNNING COMPREHENSIVE ENDOGENEITY TESTING\")\n",
    "        \n",
    "        try:\n",
    "            self.load_and_prepare_data()\n",
    "            self.run_all_endogeneity_tests()\n",
    "            self.print_summary_results()\n",
    "            \n",
    "            # Create and save Word document\n",
    "            word_filename = self.save_word_document()\n",
    "            \n",
    "            print(f\"\\n Complete endogeneity analysis saved to: {word_filename}\")\n",
    "            \n",
    "            return self.results\n",
    "        except Exception as e:\n",
    "            print(f\" Critical error in endogeneity testing: {str(e)}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return None\n",
    "\n",
    "\n",
    "# USAGE CODE FOR YOUR SPECIFIC PATH\n",
    "if __name__ == \"__main__\":\n",
    "    # Your file paths\n",
    "    data_path = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/final_clean_dataset_filtered_with_corrected_factor_loadings_with_robust_momentum.csv\"\n",
    "    \n",
    "    # Your specified output directory\n",
    "    output_dir = \"/Users/daniel/Library/Mobile Documents/com~apple~CloudDocs/Documents/Master Finance/MasterThesis/ThesisData/Regression/RegressionTables/EndogeneityTesting/\"\n",
    "    \n",
    "    import os\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"❌ERROR: Data file not found at {data_path}\")\n",
    "    else:\n",
    "        # Run endogeneity testing with Word document export\n",
    "        tester = EndogeneityTesterWithWordExport(data_path=data_path, output_path=output_dir)\n",
    "        results = tester.run_complete_endogeneity_analysis()\n",
    "        \n",
    "        if results:\n",
    "            print(f\"\\n ENDOGENEITY TESTING COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\" Word document saved to: {output_dir}\")\n",
    "            print(f\" Tables include:\")\n",
    "            print(f\"   - Table 1: Omitted Variable Bias Test\")\n",
    "            print(f\"   - Table 2: Reverse Causality Test\") \n",
    "            print(f\"   - Table 3: Coefficient Stability Test\")\n",
    "            print(f\"   - Summary and interpretation section\")\n",
    "            print(f\"   - Technical details and variable definitions\")\n",
    "        else:\n",
    "            print(f\"\\n Endogeneity testing failed.\")\n",
    "\n",
    "\n",
    "# TO RUN WITH YOUR DATA:\n",
    "# 1. Copy this entire code\n",
    "# 2. Run it - it will automatically create the Word document in your specified directory\n",
    "# 3. The Word document will contain publication-ready tables and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0165a4a-bf83-45dd-81d0-9a5abcfe5305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
